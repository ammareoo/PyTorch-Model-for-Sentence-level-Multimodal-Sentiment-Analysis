{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcca9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8721a70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "      <td>['plate', 'delicious', 'food', 'including', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "      <td>['french', 'fry', 'healthy', 'food', 'excellen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "      <td>['plate', 'one', 'favorite', 'food', 'french',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "      <td>['disgusting', 'food', 'bad', 'food']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "      <td>['plate', 'disgusting', 'food', 'found', 'diner']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>39194</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "      <td>['dirty', 'bathroom', 'dirty', 'window', 'made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>39195</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "      <td>['dirty', 'bathroom', 'window']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>39196</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "      <td>['towel', 'rack', 'dirty', 'bathroom']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>39197</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "      <td>['dirty', 'bathroom', 'dirty', 'window', 'made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "      <td>['dirty', 'bathroom', 'window']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39199 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "39194       39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195       39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196       39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197       39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198       39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \\\n",
       "0      a plate of delicious food including French fries.   \n",
       "1      French fries are not a healthy food but it is ...   \n",
       "2      The plate has one of my favorite foods on it, ...   \n",
       "3             It was disgusting food, not just bad food.   \n",
       "4           A plate of disgusting food found at a diner.   \n",
       "...                                                  ...   \n",
       "39194  A dirty bathroom that has a dirty window made ...   \n",
       "39195          A dirty bathroom that has a window in it.   \n",
       "39196      a towel that is on a rack in a dirty bathroom   \n",
       "39197  A dirty bathroom that has a dirty window made ...   \n",
       "39198          A dirty bathroom that has a window in it.   \n",
       "\n",
       "                                            clean_tokens  \n",
       "0      ['plate', 'delicious', 'food', 'including', 'f...  \n",
       "1      ['french', 'fry', 'healthy', 'food', 'excellen...  \n",
       "2      ['plate', 'one', 'favorite', 'food', 'french',...  \n",
       "3                  ['disgusting', 'food', 'bad', 'food']  \n",
       "4      ['plate', 'disgusting', 'food', 'found', 'diner']  \n",
       "...                                                  ...  \n",
       "39194  ['dirty', 'bathroom', 'dirty', 'window', 'made...  \n",
       "39195                    ['dirty', 'bathroom', 'window']  \n",
       "39196             ['towel', 'rack', 'dirty', 'bathroom']  \n",
       "39197  ['dirty', 'bathroom', 'dirty', 'window', 'made...  \n",
       "39198                    ['dirty', 'bathroom', 'window']  \n",
       "\n",
       "[39199 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('sentiment.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce8be32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a', 'plate', 'of', 'delicious', 'food', 'including', 'french', 'fries']\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958fa6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [ast.literal_eval(string_list) for string_list in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b602dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_list= [ast.literal_eval(string_list) for string_list in df['word_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7161d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "385e2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words_list = [[my_list[i][j] for j in range(len(sentiment_list[i])) if sentiment_list[i][j] == 1] for i in range(len(sentiment_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "266ce328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delicious', 'food']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2c52451",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,a in enumerate(filtered_words_list): #fill in the empty lists\n",
    "    if (len(a)==0):\n",
    "        filtered_words_list[i].append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "969c185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69830a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' '.join(words) for words in filtered_words_list]\n",
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01a2ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=features.toarray()\n",
    "hello=[torch.tensor(i) for i in hello]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12e6eac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hello[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40c28638",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_list=[torch.tensor(sent) for sent in df['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cc066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "752ff9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModel, self).__init__()\n",
    "        self.l1 = nn.Linear(541, 200)\n",
    "        self.l2 = nn.Linear(200, 100)\n",
    "        self.l3 = nn.Linear(100, 36)\n",
    "        self.l4 = nn.Linear(36, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tan=nn.Tanh()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, features):\n",
    "        hello = self.l1(features.to(torch.float32))\n",
    "        hello = self.relu(hello)\n",
    "        hello = self.l2(hello)\n",
    "        hello = self.tan(hello)\n",
    "        hello = self.l3(hello)\n",
    "        hello = self.sig(hello)\n",
    "        hello = self.l4(hello)\n",
    "        return hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3cad68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, texts, sentiments):\n",
    "        self.texts = texts\n",
    "        self.sentiments = sentiments\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        sentiment = self.sentiments[index]\n",
    "        return (text, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e95b2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and testing before being used\n",
    "word_train, word_test,sentiments_train, sentiments_test = train_test_split(hello, sentiment_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dc0333c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a dataset object and a dataloader object for the train set\n",
    "train_dataset = MultimodalDataset(word_train, sentiments_train)\n",
    "batch_size = 75\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# create a dataset object and a dataloader object for the test set\n",
    "test_dataset = MultimodalDataset(word_test, sentiments_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b648db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, (text_feats, sentiment_labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text_feats) \n",
    "        output = torch.sigmoid(output)\n",
    "        loss = loss_fn(output.squeeze(), sentiment_labels.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 2 == 0:\n",
    "            loss, current = loss.item(), batch * len(text_feats)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(test_dataloader, model, loss_fn):\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_feats, sentiment_labels in test_dataloader:\n",
    "            output = model(text_feats)\n",
    "            correct += (output.round() == sentiment_labels).type(torch.float).item()\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, For overall_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a95655d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def test_loop2(test_dataloader, model, loss_fn):\n",
    "    size = len(test_dataloader.dataset)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text_feats, sentiment_labels in test_dataloader:\n",
    "            output = model(text_feats)\n",
    "            output = torch.sigmoid(output) \n",
    "            _, predicted = torch.max(output, dim=1)\n",
    "            correct += (predicted == sentiment_labels).sum().item()\n",
    "            \n",
    "            y_true.extend(sentiment_labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "\n",
    "    accuracy = correct / size\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dc8f1268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.686058  [    0/31359]\n",
      "loss: 0.664632  [  150/31359]\n",
      "loss: 0.634395  [  300/31359]\n",
      "loss: 0.532661  [  450/31359]\n",
      "loss: 0.395107  [  600/31359]\n",
      "loss: 0.230380  [  750/31359]\n",
      "loss: 0.148934  [  900/31359]\n",
      "loss: 0.099377  [ 1050/31359]\n",
      "loss: 0.121738  [ 1200/31359]\n",
      "loss: 0.059645  [ 1350/31359]\n",
      "loss: 0.064799  [ 1500/31359]\n",
      "loss: 0.032401  [ 1650/31359]\n",
      "loss: 0.025179  [ 1800/31359]\n",
      "loss: 0.137258  [ 1950/31359]\n",
      "loss: 0.016936  [ 2100/31359]\n",
      "loss: 0.015207  [ 2250/31359]\n",
      "loss: 0.012884  [ 2400/31359]\n",
      "loss: 0.075735  [ 2550/31359]\n",
      "loss: 0.009936  [ 2700/31359]\n",
      "loss: 0.008076  [ 2850/31359]\n",
      "loss: 0.152119  [ 3000/31359]\n",
      "loss: 0.041972  [ 3150/31359]\n",
      "loss: 0.079195  [ 3300/31359]\n",
      "loss: 0.008190  [ 3450/31359]\n",
      "loss: 0.007267  [ 3600/31359]\n",
      "loss: 0.118655  [ 3750/31359]\n",
      "loss: 0.019378  [ 3900/31359]\n",
      "loss: 0.056591  [ 4050/31359]\n",
      "loss: 0.026303  [ 4200/31359]\n",
      "loss: 0.055033  [ 4350/31359]\n",
      "loss: 0.006608  [ 4500/31359]\n",
      "loss: 0.006474  [ 4650/31359]\n",
      "loss: 0.006245  [ 4800/31359]\n",
      "loss: 0.011157  [ 4950/31359]\n",
      "loss: 0.005798  [ 5100/31359]\n",
      "loss: 0.005444  [ 5250/31359]\n",
      "loss: 0.005585  [ 5400/31359]\n",
      "loss: 0.019512  [ 5550/31359]\n",
      "loss: 0.072359  [ 5700/31359]\n",
      "loss: 0.072002  [ 5850/31359]\n",
      "loss: 0.005057  [ 6000/31359]\n",
      "loss: 0.005111  [ 6150/31359]\n",
      "loss: 0.004869  [ 6300/31359]\n",
      "loss: 0.106042  [ 6450/31359]\n",
      "loss: 0.005093  [ 6600/31359]\n",
      "loss: 0.005109  [ 6750/31359]\n",
      "loss: 0.004499  [ 6900/31359]\n",
      "loss: 0.067002  [ 7050/31359]\n",
      "loss: 0.004676  [ 7200/31359]\n",
      "loss: 0.054853  [ 7350/31359]\n",
      "loss: 0.004264  [ 7500/31359]\n",
      "loss: 0.004118  [ 7650/31359]\n",
      "loss: 0.004762  [ 7800/31359]\n",
      "loss: 0.004318  [ 7950/31359]\n",
      "loss: 0.004211  [ 8100/31359]\n",
      "loss: 0.007698  [ 8250/31359]\n",
      "loss: 0.004865  [ 8400/31359]\n",
      "loss: 0.082204  [ 8550/31359]\n",
      "loss: 0.011605  [ 8700/31359]\n",
      "loss: 0.004396  [ 8850/31359]\n",
      "loss: 0.003966  [ 9000/31359]\n",
      "loss: 0.004085  [ 9150/31359]\n",
      "loss: 0.006574  [ 9300/31359]\n",
      "loss: 0.003725  [ 9450/31359]\n",
      "loss: 0.003741  [ 9600/31359]\n",
      "loss: 0.003502  [ 9750/31359]\n",
      "loss: 0.003468  [ 9900/31359]\n",
      "loss: 0.003183  [10050/31359]\n",
      "loss: 0.003446  [10200/31359]\n",
      "loss: 0.003126  [10350/31359]\n",
      "loss: 0.003020  [10500/31359]\n",
      "loss: 0.002936  [10650/31359]\n",
      "loss: 0.090049  [10800/31359]\n",
      "loss: 0.002806  [10950/31359]\n",
      "loss: 0.002780  [11100/31359]\n",
      "loss: 0.078952  [11250/31359]\n",
      "loss: 0.002857  [11400/31359]\n",
      "loss: 0.003134  [11550/31359]\n",
      "loss: 0.003266  [11700/31359]\n",
      "loss: 0.003430  [11850/31359]\n",
      "loss: 0.003034  [12000/31359]\n",
      "loss: 0.003356  [12150/31359]\n",
      "loss: 0.073172  [12300/31359]\n",
      "loss: 0.002489  [12450/31359]\n",
      "loss: 0.080208  [12600/31359]\n",
      "loss: 0.002590  [12750/31359]\n",
      "loss: 0.002804  [12900/31359]\n",
      "loss: 0.003461  [13050/31359]\n",
      "loss: 0.003961  [13200/31359]\n",
      "loss: 0.004270  [13350/31359]\n",
      "loss: 0.003823  [13500/31359]\n",
      "loss: 0.003416  [13650/31359]\n",
      "loss: 0.033500  [13800/31359]\n",
      "loss: 0.002910  [13950/31359]\n",
      "loss: 0.002738  [14100/31359]\n",
      "loss: 0.011181  [14250/31359]\n",
      "loss: 0.002546  [14400/31359]\n",
      "loss: 0.002457  [14550/31359]\n",
      "loss: 0.002396  [14700/31359]\n",
      "loss: 0.002365  [14850/31359]\n",
      "loss: 0.002211  [15000/31359]\n",
      "loss: 0.075379  [15150/31359]\n",
      "loss: 0.002125  [15300/31359]\n",
      "loss: 0.002146  [15450/31359]\n",
      "loss: 0.002081  [15600/31359]\n",
      "loss: 0.002099  [15750/31359]\n",
      "loss: 0.075073  [15900/31359]\n",
      "loss: 0.002036  [16050/31359]\n",
      "loss: 0.002061  [16200/31359]\n",
      "loss: 0.002041  [16350/31359]\n",
      "loss: 0.002081  [16500/31359]\n",
      "loss: 0.051336  [16650/31359]\n",
      "loss: 0.023106  [16800/31359]\n",
      "loss: 0.003674  [16950/31359]\n",
      "loss: 0.003990  [17100/31359]\n",
      "loss: 0.003617  [17250/31359]\n",
      "loss: 0.076852  [17400/31359]\n",
      "loss: 0.003582  [17550/31359]\n",
      "loss: 0.063783  [17700/31359]\n",
      "loss: 0.006371  [17850/31359]\n",
      "loss: 0.003980  [18000/31359]\n",
      "loss: 0.002633  [18150/31359]\n",
      "loss: 0.002437  [18300/31359]\n",
      "loss: 0.002634  [18450/31359]\n",
      "loss: 0.003014  [18600/31359]\n",
      "loss: 0.003760  [18750/31359]\n",
      "loss: 0.014644  [18900/31359]\n",
      "loss: 0.003008  [19050/31359]\n",
      "loss: 0.002507  [19200/31359]\n",
      "loss: 0.002090  [19350/31359]\n",
      "loss: 0.054620  [19500/31359]\n",
      "loss: 0.001925  [19650/31359]\n",
      "loss: 0.002375  [19800/31359]\n",
      "loss: 0.001728  [19950/31359]\n",
      "loss: 0.003129  [20100/31359]\n",
      "loss: 0.001581  [20250/31359]\n",
      "loss: 0.001588  [20400/31359]\n",
      "loss: 0.001611  [20550/31359]\n",
      "loss: 0.044636  [20700/31359]\n",
      "loss: 0.001344  [20850/31359]\n",
      "loss: 0.001382  [21000/31359]\n",
      "loss: 0.001364  [21150/31359]\n",
      "loss: 0.004202  [21300/31359]\n",
      "loss: 0.001393  [21450/31359]\n",
      "loss: 0.001284  [21600/31359]\n",
      "loss: 0.001670  [21750/31359]\n",
      "loss: 0.001226  [21900/31359]\n",
      "loss: 0.058560  [22050/31359]\n",
      "loss: 0.001237  [22200/31359]\n",
      "loss: 0.029478  [22350/31359]\n",
      "loss: 0.001616  [22500/31359]\n",
      "loss: 0.002065  [22650/31359]\n",
      "loss: 0.002327  [22800/31359]\n",
      "loss: 0.002336  [22950/31359]\n",
      "loss: 0.002287  [23100/31359]\n",
      "loss: 0.002195  [23250/31359]\n",
      "loss: 0.002301  [23400/31359]\n",
      "loss: 0.001675  [23550/31359]\n",
      "loss: 0.001741  [23700/31359]\n",
      "loss: 0.001488  [23850/31359]\n",
      "loss: 0.001437  [24000/31359]\n",
      "loss: 0.001276  [24150/31359]\n",
      "loss: 0.001358  [24300/31359]\n",
      "loss: 0.047126  [24450/31359]\n",
      "loss: 0.001555  [24600/31359]\n",
      "loss: 0.030346  [24750/31359]\n",
      "loss: 0.001783  [24900/31359]\n",
      "loss: 0.001827  [25050/31359]\n",
      "loss: 0.001831  [25200/31359]\n",
      "loss: 0.001752  [25350/31359]\n",
      "loss: 0.001684  [25500/31359]\n",
      "loss: 0.001563  [25650/31359]\n",
      "loss: 0.004296  [25800/31359]\n",
      "loss: 0.001234  [25950/31359]\n",
      "loss: 0.001121  [26100/31359]\n",
      "loss: 0.001052  [26250/31359]\n",
      "loss: 0.001018  [26400/31359]\n",
      "loss: 0.001039  [26550/31359]\n",
      "loss: 0.003057  [26700/31359]\n",
      "loss: 0.024737  [26850/31359]\n",
      "loss: 0.001064  [27000/31359]\n",
      "loss: 0.001125  [27150/31359]\n",
      "loss: 0.001086  [27300/31359]\n",
      "loss: 0.001200  [27450/31359]\n",
      "loss: 0.052384  [27600/31359]\n",
      "loss: 0.001332  [27750/31359]\n",
      "loss: 0.002422  [27900/31359]\n",
      "loss: 0.009425  [28050/31359]\n",
      "loss: 0.018311  [28200/31359]\n",
      "loss: 0.001763  [28350/31359]\n",
      "loss: 0.001190  [28500/31359]\n",
      "loss: 0.000978  [28650/31359]\n",
      "loss: 0.000883  [28800/31359]\n",
      "loss: 0.000839  [28950/31359]\n",
      "loss: 0.000924  [29100/31359]\n",
      "loss: 0.000790  [29250/31359]\n",
      "loss: 0.000813  [29400/31359]\n",
      "loss: 0.000751  [29550/31359]\n",
      "loss: 0.000736  [29700/31359]\n",
      "loss: 0.000731  [29850/31359]\n",
      "loss: 0.000711  [30000/31359]\n",
      "loss: 0.000718  [30150/31359]\n",
      "loss: 0.000692  [30300/31359]\n",
      "loss: 0.000681  [30450/31359]\n",
      "loss: 0.000675  [30600/31359]\n",
      "loss: 0.000671  [30750/31359]\n",
      "loss: 0.000693  [30900/31359]\n",
      "loss: 0.078875  [31050/31359]\n",
      "loss: 0.000671  [31200/31359]\n",
      "loss: 0.000697  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.000812  [    0/31359]\n",
      "loss: 0.000885  [  150/31359]\n",
      "loss: 0.000990  [  300/31359]\n",
      "loss: 0.000662  [  450/31359]\n",
      "loss: 0.001177  [  600/31359]\n",
      "loss: 0.001211  [  750/31359]\n",
      "loss: 0.000654  [  900/31359]\n",
      "loss: 0.000674  [ 1050/31359]\n",
      "loss: 0.033671  [ 1200/31359]\n",
      "loss: 0.029965  [ 1350/31359]\n",
      "loss: 0.000715  [ 1500/31359]\n",
      "loss: 0.000734  [ 1650/31359]\n",
      "loss: 0.000801  [ 1800/31359]\n",
      "loss: 0.005442  [ 1950/31359]\n",
      "loss: 0.001033  [ 2100/31359]\n",
      "loss: 0.001099  [ 2250/31359]\n",
      "loss: 0.001110  [ 2400/31359]\n",
      "loss: 0.018356  [ 2550/31359]\n",
      "loss: 0.000949  [ 2700/31359]\n",
      "loss: 0.000796  [ 2850/31359]\n",
      "loss: 0.062008  [ 3000/31359]\n",
      "loss: 0.000909  [ 3150/31359]\n",
      "loss: 0.001048  [ 3300/31359]\n",
      "loss: 0.001198  [ 3450/31359]\n",
      "loss: 0.007108  [ 3600/31359]\n",
      "loss: 0.001243  [ 3750/31359]\n",
      "loss: 0.003395  [ 3900/31359]\n",
      "loss: 0.001087  [ 4050/31359]\n",
      "loss: 0.003349  [ 4200/31359]\n",
      "loss: 0.004058  [ 4350/31359]\n",
      "loss: 0.001202  [ 4500/31359]\n",
      "loss: 0.001096  [ 4650/31359]\n",
      "loss: 0.000992  [ 4800/31359]\n",
      "loss: 0.021241  [ 4950/31359]\n",
      "loss: 0.000830  [ 5100/31359]\n",
      "loss: 0.000771  [ 5250/31359]\n",
      "loss: 0.000791  [ 5400/31359]\n",
      "loss: 0.000701  [ 5550/31359]\n",
      "loss: 0.012949  [ 5700/31359]\n",
      "loss: 0.011327  [ 5850/31359]\n",
      "loss: 0.000608  [ 6000/31359]\n",
      "loss: 0.000645  [ 6150/31359]\n",
      "loss: 0.000604  [ 6300/31359]\n",
      "loss: 0.000628  [ 6450/31359]\n",
      "loss: 0.006899  [ 6600/31359]\n",
      "loss: 0.000592  [ 6750/31359]\n",
      "loss: 0.000530  [ 6900/31359]\n",
      "loss: 0.000527  [ 7050/31359]\n",
      "loss: 0.000530  [ 7200/31359]\n",
      "loss: 0.021812  [ 7350/31359]\n",
      "loss: 0.000492  [ 7500/31359]\n",
      "loss: 0.000489  [ 7650/31359]\n",
      "loss: 0.000554  [ 7800/31359]\n",
      "loss: 0.000543  [ 7950/31359]\n",
      "loss: 0.000578  [ 8100/31359]\n",
      "loss: 0.002822  [ 8250/31359]\n",
      "loss: 0.002784  [ 8400/31359]\n",
      "loss: 0.000921  [ 8550/31359]\n",
      "loss: 0.004666  [ 8700/31359]\n",
      "loss: 0.001027  [ 8850/31359]\n",
      "loss: 0.001324  [ 9000/31359]\n",
      "loss: 0.001580  [ 9150/31359]\n",
      "loss: 0.001304  [ 9300/31359]\n",
      "loss: 0.001060  [ 9450/31359]\n",
      "loss: 0.000779  [ 9600/31359]\n",
      "loss: 0.000646  [ 9750/31359]\n",
      "loss: 0.000572  [ 9900/31359]\n",
      "loss: 0.000518  [10050/31359]\n",
      "loss: 0.000638  [10200/31359]\n",
      "loss: 0.000459  [10350/31359]\n",
      "loss: 0.000440  [10500/31359]\n",
      "loss: 0.000428  [10650/31359]\n",
      "loss: 0.174670  [10800/31359]\n",
      "loss: 0.000470  [10950/31359]\n",
      "loss: 0.000553  [11100/31359]\n",
      "loss: 0.000878  [11250/31359]\n",
      "loss: 0.000780  [11400/31359]\n",
      "loss: 0.000876  [11550/31359]\n",
      "loss: 0.001201  [11700/31359]\n",
      "loss: 0.027169  [11850/31359]\n",
      "loss: 0.003785  [12000/31359]\n",
      "loss: 0.001883  [12150/31359]\n",
      "loss: 0.013500  [12300/31359]\n",
      "loss: 0.000634  [12450/31359]\n",
      "loss: 0.019078  [12600/31359]\n",
      "loss: 0.000474  [12750/31359]\n",
      "loss: 0.000414  [12900/31359]\n",
      "loss: 0.000429  [13050/31359]\n",
      "loss: 0.000346  [13200/31359]\n",
      "loss: 0.000379  [13350/31359]\n",
      "loss: 0.000367  [13500/31359]\n",
      "loss: 0.000377  [13650/31359]\n",
      "loss: 0.000402  [13800/31359]\n",
      "loss: 0.000367  [13950/31359]\n",
      "loss: 0.000430  [14100/31359]\n",
      "loss: 0.021622  [14250/31359]\n",
      "loss: 0.000407  [14400/31359]\n",
      "loss: 0.000366  [14550/31359]\n",
      "loss: 0.000370  [14700/31359]\n",
      "loss: 0.006324  [14850/31359]\n",
      "loss: 0.000380  [15000/31359]\n",
      "loss: 0.023772  [15150/31359]\n",
      "loss: 0.000385  [15300/31359]\n",
      "loss: 0.003581  [15450/31359]\n",
      "loss: 0.000390  [15600/31359]\n",
      "loss: 0.000397  [15750/31359]\n",
      "loss: 0.022297  [15900/31359]\n",
      "loss: 0.000396  [16050/31359]\n",
      "loss: 0.000431  [16200/31359]\n",
      "loss: 0.000383  [16350/31359]\n",
      "loss: 0.000414  [16500/31359]\n",
      "loss: 0.010250  [16650/31359]\n",
      "loss: 0.006686  [16800/31359]\n",
      "loss: 0.000390  [16950/31359]\n",
      "loss: 0.000384  [17100/31359]\n",
      "loss: 0.000374  [17250/31359]\n",
      "loss: 0.000372  [17400/31359]\n",
      "loss: 0.000361  [17550/31359]\n",
      "loss: 0.030455  [17700/31359]\n",
      "loss: 0.003148  [17850/31359]\n",
      "loss: 0.000627  [18000/31359]\n",
      "loss: 0.000795  [18150/31359]\n",
      "loss: 0.001023  [18300/31359]\n",
      "loss: 0.001637  [18450/31359]\n",
      "loss: 0.001786  [18600/31359]\n",
      "loss: 0.001351  [18750/31359]\n",
      "loss: 0.006621  [18900/31359]\n",
      "loss: 0.000655  [19050/31359]\n",
      "loss: 0.000522  [19200/31359]\n",
      "loss: 0.000426  [19350/31359]\n",
      "loss: 0.023009  [19500/31359]\n",
      "loss: 0.000407  [19650/31359]\n",
      "loss: 0.003690  [19800/31359]\n",
      "loss: 0.000358  [19950/31359]\n",
      "loss: 0.006797  [20100/31359]\n",
      "loss: 0.000329  [20250/31359]\n",
      "loss: 0.000348  [20400/31359]\n",
      "loss: 0.000369  [20550/31359]\n",
      "loss: 0.030724  [20700/31359]\n",
      "loss: 0.000282  [20850/31359]\n",
      "loss: 0.000297  [21000/31359]\n",
      "loss: 0.000294  [21150/31359]\n",
      "loss: 0.019398  [21300/31359]\n",
      "loss: 0.000317  [21450/31359]\n",
      "loss: 0.000276  [21600/31359]\n",
      "loss: 0.008458  [21750/31359]\n",
      "loss: 0.000266  [21900/31359]\n",
      "loss: 0.019648  [22050/31359]\n",
      "loss: 0.000263  [22200/31359]\n",
      "loss: 0.011913  [22350/31359]\n",
      "loss: 0.000304  [22500/31359]\n",
      "loss: 0.000329  [22650/31359]\n",
      "loss: 0.000355  [22800/31359]\n",
      "loss: 0.000383  [22950/31359]\n",
      "loss: 0.000375  [23100/31359]\n",
      "loss: 0.000358  [23250/31359]\n",
      "loss: 0.000423  [23400/31359]\n",
      "loss: 0.000325  [23550/31359]\n",
      "loss: 0.000396  [23700/31359]\n",
      "loss: 0.000376  [23850/31359]\n",
      "loss: 0.000375  [24000/31359]\n",
      "loss: 0.000271  [24150/31359]\n",
      "loss: 0.000288  [24300/31359]\n",
      "loss: 0.016133  [24450/31359]\n",
      "loss: 0.000313  [24600/31359]\n",
      "loss: 0.013603  [24750/31359]\n",
      "loss: 0.000282  [24900/31359]\n",
      "loss: 0.000260  [25050/31359]\n",
      "loss: 0.000252  [25200/31359]\n",
      "loss: 0.000233  [25350/31359]\n",
      "loss: 0.000246  [25500/31359]\n",
      "loss: 0.000271  [25650/31359]\n",
      "loss: 0.006511  [25800/31359]\n",
      "loss: 0.000235  [25950/31359]\n",
      "loss: 0.000228  [26100/31359]\n",
      "loss: 0.000233  [26250/31359]\n",
      "loss: 0.000225  [26400/31359]\n",
      "loss: 0.000237  [26550/31359]\n",
      "loss: 0.003860  [26700/31359]\n",
      "loss: 0.019388  [26850/31359]\n",
      "loss: 0.000251  [27000/31359]\n",
      "loss: 0.000271  [27150/31359]\n",
      "loss: 0.000252  [27300/31359]\n",
      "loss: 0.000299  [27450/31359]\n",
      "loss: 0.011950  [27600/31359]\n",
      "loss: 0.000337  [27750/31359]\n",
      "loss: 0.000302  [27900/31359]\n",
      "loss: 0.000318  [28050/31359]\n",
      "loss: 0.007361  [28200/31359]\n",
      "loss: 0.000300  [28350/31359]\n",
      "loss: 0.000290  [28500/31359]\n",
      "loss: 0.000296  [28650/31359]\n",
      "loss: 0.000276  [28800/31359]\n",
      "loss: 0.000258  [28950/31359]\n",
      "loss: 0.002419  [29100/31359]\n",
      "loss: 0.000244  [29250/31359]\n",
      "loss: 0.001804  [29400/31359]\n",
      "loss: 0.000244  [29550/31359]\n",
      "loss: 0.000239  [29700/31359]\n",
      "loss: 0.000227  [29850/31359]\n",
      "loss: 0.000231  [30000/31359]\n",
      "loss: 0.001094  [30150/31359]\n",
      "loss: 0.000224  [30300/31359]\n",
      "loss: 0.000217  [30450/31359]\n",
      "loss: 0.000219  [30600/31359]\n",
      "loss: 0.000224  [30750/31359]\n",
      "loss: 0.001569  [30900/31359]\n",
      "loss: 0.029933  [31050/31359]\n",
      "loss: 0.000250  [31200/31359]\n",
      "loss: 0.000288  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.003236  [    0/31359]\n",
      "loss: 0.003495  [  150/31359]\n",
      "loss: 0.003483  [  300/31359]\n",
      "loss: 0.000253  [  450/31359]\n",
      "loss: 0.002973  [  600/31359]\n",
      "loss: 0.002643  [  750/31359]\n",
      "loss: 0.000226  [  900/31359]\n",
      "loss: 0.000232  [ 1050/31359]\n",
      "loss: 0.049085  [ 1200/31359]\n",
      "loss: 0.003905  [ 1350/31359]\n",
      "loss: 0.000286  [ 1500/31359]\n",
      "loss: 0.000301  [ 1650/31359]\n",
      "loss: 0.000316  [ 1800/31359]\n",
      "loss: 0.012745  [ 1950/31359]\n",
      "loss: 0.000333  [ 2100/31359]\n",
      "loss: 0.000347  [ 2250/31359]\n",
      "loss: 0.000331  [ 2400/31359]\n",
      "loss: 0.018484  [ 2550/31359]\n",
      "loss: 0.000310  [ 2700/31359]\n",
      "loss: 0.000265  [ 2850/31359]\n",
      "loss: 0.030371  [ 3000/31359]\n",
      "loss: 0.000320  [ 3150/31359]\n",
      "loss: 0.000317  [ 3300/31359]\n",
      "loss: 0.000348  [ 3450/31359]\n",
      "loss: 0.012254  [ 3600/31359]\n",
      "loss: 0.000276  [ 3750/31359]\n",
      "loss: 0.009505  [ 3900/31359]\n",
      "loss: 0.000259  [ 4050/31359]\n",
      "loss: 0.008016  [ 4200/31359]\n",
      "loss: 0.007608  [ 4350/31359]\n",
      "loss: 0.000248  [ 4500/31359]\n",
      "loss: 0.000240  [ 4650/31359]\n",
      "loss: 0.000230  [ 4800/31359]\n",
      "loss: 0.015612  [ 4950/31359]\n",
      "loss: 0.000219  [ 5100/31359]\n",
      "loss: 0.000212  [ 5250/31359]\n",
      "loss: 0.000235  [ 5400/31359]\n",
      "loss: 0.000217  [ 5550/31359]\n",
      "loss: 0.007467  [ 5700/31359]\n",
      "loss: 0.007227  [ 5850/31359]\n",
      "loss: 0.000194  [ 6000/31359]\n",
      "loss: 0.000218  [ 6150/31359]\n",
      "loss: 0.000205  [ 6300/31359]\n",
      "loss: 0.000198  [ 6450/31359]\n",
      "loss: 0.007209  [ 6600/31359]\n",
      "loss: 0.000210  [ 6750/31359]\n",
      "loss: 0.000185  [ 6900/31359]\n",
      "loss: 0.000184  [ 7050/31359]\n",
      "loss: 0.000191  [ 7200/31359]\n",
      "loss: 0.014311  [ 7350/31359]\n",
      "loss: 0.000175  [ 7500/31359]\n",
      "loss: 0.000173  [ 7650/31359]\n",
      "loss: 0.000201  [ 7800/31359]\n",
      "loss: 0.000194  [ 7950/31359]\n",
      "loss: 0.000197  [ 8100/31359]\n",
      "loss: 0.007420  [ 8250/31359]\n",
      "loss: 0.006441  [ 8400/31359]\n",
      "loss: 0.000207  [ 8550/31359]\n",
      "loss: 0.005669  [ 8700/31359]\n",
      "loss: 0.000234  [ 8850/31359]\n",
      "loss: 0.000218  [ 9000/31359]\n",
      "loss: 0.000233  [ 9150/31359]\n",
      "loss: 0.000230  [ 9300/31359]\n",
      "loss: 0.000227  [ 9450/31359]\n",
      "loss: 0.000233  [ 9600/31359]\n",
      "loss: 0.000219  [ 9750/31359]\n",
      "loss: 0.000214  [ 9900/31359]\n",
      "loss: 0.000203  [10050/31359]\n",
      "loss: 0.014174  [10200/31359]\n",
      "loss: 0.000191  [10350/31359]\n",
      "loss: 0.000182  [10500/31359]\n",
      "loss: 0.000176  [10650/31359]\n",
      "loss: 0.042107  [10800/31359]\n",
      "loss: 0.000180  [10950/31359]\n",
      "loss: 0.000189  [11100/31359]\n",
      "loss: 0.005168  [11250/31359]\n",
      "loss: 0.000194  [11400/31359]\n",
      "loss: 0.000198  [11550/31359]\n",
      "loss: 0.000201  [11700/31359]\n",
      "loss: 0.014437  [11850/31359]\n",
      "loss: 0.000219  [12000/31359]\n",
      "loss: 0.000221  [12150/31359]\n",
      "loss: 0.010618  [12300/31359]\n",
      "loss: 0.000227  [12450/31359]\n",
      "loss: 0.018794  [12600/31359]\n",
      "loss: 0.000233  [12750/31359]\n",
      "loss: 0.000219  [12900/31359]\n",
      "loss: 0.000231  [13050/31359]\n",
      "loss: 0.000197  [13200/31359]\n",
      "loss: 0.000208  [13350/31359]\n",
      "loss: 0.000200  [13500/31359]\n",
      "loss: 0.000200  [13650/31359]\n",
      "loss: 0.000202  [13800/31359]\n",
      "loss: 0.000187  [13950/31359]\n",
      "loss: 0.000200  [14100/31359]\n",
      "loss: 0.013292  [14250/31359]\n",
      "loss: 0.000187  [14400/31359]\n",
      "loss: 0.000173  [14550/31359]\n",
      "loss: 0.000171  [14700/31359]\n",
      "loss: 0.011082  [14850/31359]\n",
      "loss: 0.000170  [15000/31359]\n",
      "loss: 0.009963  [15150/31359]\n",
      "loss: 0.000167  [15300/31359]\n",
      "loss: 0.007933  [15450/31359]\n",
      "loss: 0.000164  [15600/31359]\n",
      "loss: 0.000164  [15750/31359]\n",
      "loss: 0.013973  [15900/31359]\n",
      "loss: 0.000159  [16050/31359]\n",
      "loss: 0.000170  [16200/31359]\n",
      "loss: 0.000149  [16350/31359]\n",
      "loss: 0.000159  [16500/31359]\n",
      "loss: 0.012799  [16650/31359]\n",
      "loss: 0.010702  [16800/31359]\n",
      "loss: 0.000161  [16950/31359]\n",
      "loss: 0.000165  [17100/31359]\n",
      "loss: 0.000166  [17250/31359]\n",
      "loss: 0.000167  [17400/31359]\n",
      "loss: 0.000166  [17550/31359]\n",
      "loss: 0.015631  [17700/31359]\n",
      "loss: 0.005906  [17850/31359]\n",
      "loss: 0.000195  [18000/31359]\n",
      "loss: 0.000205  [18150/31359]\n",
      "loss: 0.000207  [18300/31359]\n",
      "loss: 0.000243  [18450/31359]\n",
      "loss: 0.000269  [18600/31359]\n",
      "loss: 0.000333  [18750/31359]\n",
      "loss: 0.006955  [18900/31359]\n",
      "loss: 0.000328  [19050/31359]\n",
      "loss: 0.000305  [19200/31359]\n",
      "loss: 0.000262  [19350/31359]\n",
      "loss: 0.018303  [19500/31359]\n",
      "loss: 0.000251  [19650/31359]\n",
      "loss: 0.004198  [19800/31359]\n",
      "loss: 0.000211  [19950/31359]\n",
      "loss: 0.007475  [20100/31359]\n",
      "loss: 0.000180  [20250/31359]\n",
      "loss: 0.000184  [20400/31359]\n",
      "loss: 0.000189  [20550/31359]\n",
      "loss: 0.024812  [20700/31359]\n",
      "loss: 0.000142  [20850/31359]\n",
      "loss: 0.000150  [21000/31359]\n",
      "loss: 0.000148  [21150/31359]\n",
      "loss: 0.021211  [21300/31359]\n",
      "loss: 0.000162  [21450/31359]\n",
      "loss: 0.000143  [21600/31359]\n",
      "loss: 0.015726  [21750/31359]\n",
      "loss: 0.000141  [21900/31359]\n",
      "loss: 0.007431  [22050/31359]\n",
      "loss: 0.000140  [22200/31359]\n",
      "loss: 0.007548  [22350/31359]\n",
      "loss: 0.000147  [22500/31359]\n",
      "loss: 0.000152  [22650/31359]\n",
      "loss: 0.000155  [22800/31359]\n",
      "loss: 0.000157  [22950/31359]\n",
      "loss: 0.000147  [23100/31359]\n",
      "loss: 0.000137  [23250/31359]\n",
      "loss: 0.000152  [23400/31359]\n",
      "loss: 0.000122  [23550/31359]\n",
      "loss: 0.000139  [23700/31359]\n",
      "loss: 0.000133  [23850/31359]\n",
      "loss: 0.000130  [24000/31359]\n",
      "loss: 0.000113  [24150/31359]\n",
      "loss: 0.000123  [24300/31359]\n",
      "loss: 0.010494  [24450/31359]\n",
      "loss: 0.000138  [24600/31359]\n",
      "loss: 0.009770  [24750/31359]\n",
      "loss: 0.000127  [24900/31359]\n",
      "loss: 0.000118  [25050/31359]\n",
      "loss: 0.000115  [25200/31359]\n",
      "loss: 0.000108  [25350/31359]\n",
      "loss: 0.000114  [25500/31359]\n",
      "loss: 0.000123  [25650/31359]\n",
      "loss: 0.006932  [25800/31359]\n",
      "loss: 0.000108  [25950/31359]\n",
      "loss: 0.000105  [26100/31359]\n",
      "loss: 0.000106  [26250/31359]\n",
      "loss: 0.000103  [26400/31359]\n",
      "loss: 0.000108  [26550/31359]\n",
      "loss: 0.004688  [26700/31359]\n",
      "loss: 0.016807  [26850/31359]\n",
      "loss: 0.000114  [27000/31359]\n",
      "loss: 0.000124  [27150/31359]\n",
      "loss: 0.000120  [27300/31359]\n",
      "loss: 0.000141  [27450/31359]\n",
      "loss: 0.010885  [27600/31359]\n",
      "loss: 0.000167  [27750/31359]\n",
      "loss: 0.000143  [27900/31359]\n",
      "loss: 0.000144  [28050/31359]\n",
      "loss: 0.007128  [28200/31359]\n",
      "loss: 0.000132  [28350/31359]\n",
      "loss: 0.000128  [28500/31359]\n",
      "loss: 0.000128  [28650/31359]\n",
      "loss: 0.000122  [28800/31359]\n",
      "loss: 0.000118  [28950/31359]\n",
      "loss: 0.002522  [29100/31359]\n",
      "loss: 0.000115  [29250/31359]\n",
      "loss: 0.001882  [29400/31359]\n",
      "loss: 0.000111  [29550/31359]\n",
      "loss: 0.000109  [29700/31359]\n",
      "loss: 0.000110  [29850/31359]\n",
      "loss: 0.000107  [30000/31359]\n",
      "loss: 0.001112  [30150/31359]\n",
      "loss: 0.000106  [30300/31359]\n",
      "loss: 0.000106  [30450/31359]\n",
      "loss: 0.000106  [30600/31359]\n",
      "loss: 0.000109  [30750/31359]\n",
      "loss: 0.001689  [30900/31359]\n",
      "loss: 0.027770  [31050/31359]\n",
      "loss: 0.000125  [31200/31359]\n",
      "loss: 0.000139  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.003457  [    0/31359]\n",
      "loss: 0.003709  [  150/31359]\n",
      "loss: 0.003670  [  300/31359]\n",
      "loss: 0.000144  [  450/31359]\n",
      "loss: 0.003110  [  600/31359]\n",
      "loss: 0.002766  [  750/31359]\n",
      "loss: 0.000123  [  900/31359]\n",
      "loss: 0.000120  [ 1050/31359]\n",
      "loss: 0.047445  [ 1200/31359]\n",
      "loss: 0.003851  [ 1350/31359]\n",
      "loss: 0.000177  [ 1500/31359]\n",
      "loss: 0.000206  [ 1650/31359]\n",
      "loss: 0.000230  [ 1800/31359]\n",
      "loss: 0.013303  [ 1950/31359]\n",
      "loss: 0.000249  [ 2100/31359]\n",
      "loss: 0.000246  [ 2250/31359]\n",
      "loss: 0.000226  [ 2400/31359]\n",
      "loss: 0.020020  [ 2550/31359]\n",
      "loss: 0.000183  [ 2700/31359]\n",
      "loss: 0.000149  [ 2850/31359]\n",
      "loss: 0.028445  [ 3000/31359]\n",
      "loss: 0.000169  [ 3150/31359]\n",
      "loss: 0.000170  [ 3300/31359]\n",
      "loss: 0.000189  [ 3450/31359]\n",
      "loss: 0.011743  [ 3600/31359]\n",
      "loss: 0.000170  [ 3750/31359]\n",
      "loss: 0.009315  [ 3900/31359]\n",
      "loss: 0.000170  [ 4050/31359]\n",
      "loss: 0.008048  [ 4200/31359]\n",
      "loss: 0.007681  [ 4350/31359]\n",
      "loss: 0.000158  [ 4500/31359]\n",
      "loss: 0.000150  [ 4650/31359]\n",
      "loss: 0.000143  [ 4800/31359]\n",
      "loss: 0.014559  [ 4950/31359]\n",
      "loss: 0.000133  [ 5100/31359]\n",
      "loss: 0.000128  [ 5250/31359]\n",
      "loss: 0.000134  [ 5400/31359]\n",
      "loss: 0.000126  [ 5550/31359]\n",
      "loss: 0.007410  [ 5700/31359]\n",
      "loss: 0.007172  [ 5850/31359]\n",
      "loss: 0.000113  [ 6000/31359]\n",
      "loss: 0.000120  [ 6150/31359]\n",
      "loss: 0.000114  [ 6300/31359]\n",
      "loss: 0.000110  [ 6450/31359]\n",
      "loss: 0.007085  [ 6600/31359]\n",
      "loss: 0.000113  [ 6750/31359]\n",
      "loss: 0.000103  [ 6900/31359]\n",
      "loss: 0.000102  [ 7050/31359]\n",
      "loss: 0.000104  [ 7200/31359]\n",
      "loss: 0.014044  [ 7350/31359]\n",
      "loss: 0.000097  [ 7500/31359]\n",
      "loss: 0.000095  [ 7650/31359]\n",
      "loss: 0.000106  [ 7800/31359]\n",
      "loss: 0.000102  [ 7950/31359]\n",
      "loss: 0.000103  [ 8100/31359]\n",
      "loss: 0.007511  [ 8250/31359]\n",
      "loss: 0.006451  [ 8400/31359]\n",
      "loss: 0.000101  [ 8550/31359]\n",
      "loss: 0.005628  [ 8700/31359]\n",
      "loss: 0.000122  [ 8850/31359]\n",
      "loss: 0.000120  [ 9000/31359]\n",
      "loss: 0.000134  [ 9150/31359]\n",
      "loss: 0.000139  [ 9300/31359]\n",
      "loss: 0.000142  [ 9450/31359]\n",
      "loss: 0.000148  [ 9600/31359]\n",
      "loss: 0.000142  [ 9750/31359]\n",
      "loss: 0.000140  [ 9900/31359]\n",
      "loss: 0.000135  [10050/31359]\n",
      "loss: 0.013972  [10200/31359]\n",
      "loss: 0.000125  [10350/31359]\n",
      "loss: 0.000119  [10500/31359]\n",
      "loss: 0.000114  [10650/31359]\n",
      "loss: 0.040048  [10800/31359]\n",
      "loss: 0.000121  [10950/31359]\n",
      "loss: 0.000132  [11100/31359]\n",
      "loss: 0.005157  [11250/31359]\n",
      "loss: 0.000142  [11400/31359]\n",
      "loss: 0.000141  [11550/31359]\n",
      "loss: 0.000142  [11700/31359]\n",
      "loss: 0.014543  [11850/31359]\n",
      "loss: 0.000150  [12000/31359]\n",
      "loss: 0.000151  [12150/31359]\n",
      "loss: 0.010967  [12300/31359]\n",
      "loss: 0.000146  [12450/31359]\n",
      "loss: 0.018656  [12600/31359]\n",
      "loss: 0.000141  [12750/31359]\n",
      "loss: 0.000134  [12900/31359]\n",
      "loss: 0.000142  [13050/31359]\n",
      "loss: 0.000126  [13200/31359]\n",
      "loss: 0.000134  [13350/31359]\n",
      "loss: 0.000131  [13500/31359]\n",
      "loss: 0.000130  [13650/31359]\n",
      "loss: 0.000129  [13800/31359]\n",
      "loss: 0.000121  [13950/31359]\n",
      "loss: 0.000124  [14100/31359]\n",
      "loss: 0.013161  [14250/31359]\n",
      "loss: 0.000115  [14400/31359]\n",
      "loss: 0.000107  [14550/31359]\n",
      "loss: 0.000105  [14700/31359]\n",
      "loss: 0.010966  [14850/31359]\n",
      "loss: 0.000101  [15000/31359]\n",
      "loss: 0.009937  [15150/31359]\n",
      "loss: 0.000096  [15300/31359]\n",
      "loss: 0.007817  [15450/31359]\n",
      "loss: 0.000092  [15600/31359]\n",
      "loss: 0.000091  [15750/31359]\n",
      "loss: 0.014070  [15900/31359]\n",
      "loss: 0.000089  [16050/31359]\n",
      "loss: 0.000095  [16200/31359]\n",
      "loss: 0.000084  [16350/31359]\n",
      "loss: 0.000090  [16500/31359]\n",
      "loss: 0.012748  [16650/31359]\n",
      "loss: 0.010579  [16800/31359]\n",
      "loss: 0.000102  [16950/31359]\n",
      "loss: 0.000111  [17100/31359]\n",
      "loss: 0.000117  [17250/31359]\n",
      "loss: 0.000122  [17400/31359]\n",
      "loss: 0.000127  [17550/31359]\n",
      "loss: 0.015661  [17700/31359]\n",
      "loss: 0.005710  [17850/31359]\n",
      "loss: 0.000163  [18000/31359]\n",
      "loss: 0.000166  [18150/31359]\n",
      "loss: 0.000169  [18300/31359]\n",
      "loss: 0.000190  [18450/31359]\n",
      "loss: 0.000198  [18600/31359]\n",
      "loss: 0.000224  [18750/31359]\n",
      "loss: 0.007540  [18900/31359]\n",
      "loss: 0.000189  [19050/31359]\n",
      "loss: 0.000167  [19200/31359]\n",
      "loss: 0.000140  [19350/31359]\n",
      "loss: 0.017435  [19500/31359]\n",
      "loss: 0.000138  [19650/31359]\n",
      "loss: 0.004307  [19800/31359]\n",
      "loss: 0.000121  [19950/31359]\n",
      "loss: 0.007621  [20100/31359]\n",
      "loss: 0.000103  [20250/31359]\n",
      "loss: 0.000104  [20400/31359]\n",
      "loss: 0.000107  [20550/31359]\n",
      "loss: 0.025424  [20700/31359]\n",
      "loss: 0.000081  [20850/31359]\n",
      "loss: 0.000089  [21000/31359]\n",
      "loss: 0.000090  [21150/31359]\n",
      "loss: 0.021130  [21300/31359]\n",
      "loss: 0.000107  [21450/31359]\n",
      "loss: 0.000099  [21600/31359]\n",
      "loss: 0.015439  [21750/31359]\n",
      "loss: 0.000110  [21900/31359]\n",
      "loss: 0.007359  [22050/31359]\n",
      "loss: 0.000118  [22200/31359]\n",
      "loss: 0.007555  [22350/31359]\n",
      "loss: 0.000126  [22500/31359]\n",
      "loss: 0.000130  [22650/31359]\n",
      "loss: 0.000129  [22800/31359]\n",
      "loss: 0.000127  [22950/31359]\n",
      "loss: 0.000116  [23100/31359]\n",
      "loss: 0.000105  [23250/31359]\n",
      "loss: 0.000114  [23400/31359]\n",
      "loss: 0.000088  [23550/31359]\n",
      "loss: 0.000099  [23700/31359]\n",
      "loss: 0.000093  [23850/31359]\n",
      "loss: 0.000089  [24000/31359]\n",
      "loss: 0.000075  [24150/31359]\n",
      "loss: 0.000082  [24300/31359]\n",
      "loss: 0.010395  [24450/31359]\n",
      "loss: 0.000090  [24600/31359]\n",
      "loss: 0.009712  [24750/31359]\n",
      "loss: 0.000081  [24900/31359]\n",
      "loss: 0.000075  [25050/31359]\n",
      "loss: 0.000072  [25200/31359]\n",
      "loss: 0.000068  [25350/31359]\n",
      "loss: 0.000072  [25500/31359]\n",
      "loss: 0.000078  [25650/31359]\n",
      "loss: 0.006975  [25800/31359]\n",
      "loss: 0.000067  [25950/31359]\n",
      "loss: 0.000064  [26100/31359]\n",
      "loss: 0.000064  [26250/31359]\n",
      "loss: 0.000063  [26400/31359]\n",
      "loss: 0.000067  [26550/31359]\n",
      "loss: 0.004751  [26700/31359]\n",
      "loss: 0.016533  [26850/31359]\n",
      "loss: 0.000074  [27000/31359]\n",
      "loss: 0.000084  [27150/31359]\n",
      "loss: 0.000085  [27300/31359]\n",
      "loss: 0.000104  [27450/31359]\n",
      "loss: 0.010468  [27600/31359]\n",
      "loss: 0.000132  [27750/31359]\n",
      "loss: 0.000114  [27900/31359]\n",
      "loss: 0.000115  [28050/31359]\n",
      "loss: 0.007102  [28200/31359]\n",
      "loss: 0.000103  [28350/31359]\n",
      "loss: 0.000097  [28500/31359]\n",
      "loss: 0.000094  [28650/31359]\n",
      "loss: 0.000088  [28800/31359]\n",
      "loss: 0.000084  [28950/31359]\n",
      "loss: 0.002690  [29100/31359]\n",
      "loss: 0.000079  [29250/31359]\n",
      "loss: 0.002007  [29400/31359]\n",
      "loss: 0.000072  [29550/31359]\n",
      "loss: 0.000070  [29700/31359]\n",
      "loss: 0.000072  [29850/31359]\n",
      "loss: 0.000068  [30000/31359]\n",
      "loss: 0.001156  [30150/31359]\n",
      "loss: 0.000068  [30300/31359]\n",
      "loss: 0.000068  [30450/31359]\n",
      "loss: 0.000068  [30600/31359]\n",
      "loss: 0.000071  [30750/31359]\n",
      "loss: 0.001771  [30900/31359]\n",
      "loss: 0.026896  [31050/31359]\n",
      "loss: 0.000093  [31200/31359]\n",
      "loss: 0.000106  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.003531  [    0/31359]\n",
      "loss: 0.003763  [  150/31359]\n",
      "loss: 0.003705  [  300/31359]\n",
      "loss: 0.000117  [  450/31359]\n",
      "loss: 0.003118  [  600/31359]\n",
      "loss: 0.002767  [  750/31359]\n",
      "loss: 0.000087  [  900/31359]\n",
      "loss: 0.000082  [ 1050/31359]\n",
      "loss: 0.047309  [ 1200/31359]\n",
      "loss: 0.003780  [ 1350/31359]\n",
      "loss: 0.000141  [ 1500/31359]\n",
      "loss: 0.000176  [ 1650/31359]\n",
      "loss: 0.000202  [ 1800/31359]\n",
      "loss: 0.013529  [ 1950/31359]\n",
      "loss: 0.000195  [ 2100/31359]\n",
      "loss: 0.000175  [ 2250/31359]\n",
      "loss: 0.000150  [ 2400/31359]\n",
      "loss: 0.019885  [ 2550/31359]\n",
      "loss: 0.000103  [ 2700/31359]\n",
      "loss: 0.000078  [ 2850/31359]\n",
      "loss: 0.030990  [ 3000/31359]\n",
      "loss: 0.000092  [ 3150/31359]\n",
      "loss: 0.000099  [ 3300/31359]\n",
      "loss: 0.000121  [ 3450/31359]\n",
      "loss: 0.011451  [ 3600/31359]\n",
      "loss: 0.000142  [ 3750/31359]\n",
      "loss: 0.008795  [ 3900/31359]\n",
      "loss: 0.000175  [ 4050/31359]\n",
      "loss: 0.007576  [ 4200/31359]\n",
      "loss: 0.007242  [ 4350/31359]\n",
      "loss: 0.000147  [ 4500/31359]\n",
      "loss: 0.000130  [ 4650/31359]\n",
      "loss: 0.000115  [ 4800/31359]\n",
      "loss: 0.015020  [ 4950/31359]\n",
      "loss: 0.000099  [ 5100/31359]\n",
      "loss: 0.000093  [ 5250/31359]\n",
      "loss: 0.000094  [ 5400/31359]\n",
      "loss: 0.000088  [ 5550/31359]\n",
      "loss: 0.007206  [ 5700/31359]\n",
      "loss: 0.006994  [ 5850/31359]\n",
      "loss: 0.000076  [ 6000/31359]\n",
      "loss: 0.000079  [ 6150/31359]\n",
      "loss: 0.000075  [ 6300/31359]\n",
      "loss: 0.000072  [ 6450/31359]\n",
      "loss: 0.007050  [ 6600/31359]\n",
      "loss: 0.000073  [ 6750/31359]\n",
      "loss: 0.000067  [ 6900/31359]\n",
      "loss: 0.000066  [ 7050/31359]\n",
      "loss: 0.000067  [ 7200/31359]\n",
      "loss: 0.013978  [ 7350/31359]\n",
      "loss: 0.000063  [ 7500/31359]\n",
      "loss: 0.000062  [ 7650/31359]\n",
      "loss: 0.000069  [ 7800/31359]\n",
      "loss: 0.000066  [ 7950/31359]\n",
      "loss: 0.000067  [ 8100/31359]\n",
      "loss: 0.007228  [ 8250/31359]\n",
      "loss: 0.006145  [ 8400/31359]\n",
      "loss: 0.000064  [ 8550/31359]\n",
      "loss: 0.005419  [ 8700/31359]\n",
      "loss: 0.000084  [ 8850/31359]\n",
      "loss: 0.000090  [ 9000/31359]\n",
      "loss: 0.000110  [ 9150/31359]\n",
      "loss: 0.000123  [ 9300/31359]\n",
      "loss: 0.000134  [ 9450/31359]\n",
      "loss: 0.000141  [ 9600/31359]\n",
      "loss: 0.000135  [ 9750/31359]\n",
      "loss: 0.000129  [ 9900/31359]\n",
      "loss: 0.000119  [10050/31359]\n",
      "loss: 0.012931  [10200/31359]\n",
      "loss: 0.000098  [10350/31359]\n",
      "loss: 0.000089  [10500/31359]\n",
      "loss: 0.000083  [10650/31359]\n",
      "loss: 0.041605  [10800/31359]\n",
      "loss: 0.000090  [10950/31359]\n",
      "loss: 0.000102  [11100/31359]\n",
      "loss: 0.004989  [11250/31359]\n",
      "loss: 0.000116  [11400/31359]\n",
      "loss: 0.000114  [11550/31359]\n",
      "loss: 0.000112  [11700/31359]\n",
      "loss: 0.014552  [11850/31359]\n",
      "loss: 0.000114  [12000/31359]\n",
      "loss: 0.000112  [12150/31359]\n",
      "loss: 0.010770  [12300/31359]\n",
      "loss: 0.000100  [12450/31359]\n",
      "loss: 0.018658  [12600/31359]\n",
      "loss: 0.000093  [12750/31359]\n",
      "loss: 0.000091  [12900/31359]\n",
      "loss: 0.000101  [13050/31359]\n",
      "loss: 0.000094  [13200/31359]\n",
      "loss: 0.000106  [13350/31359]\n",
      "loss: 0.000109  [13500/31359]\n",
      "loss: 0.000110  [13650/31359]\n",
      "loss: 0.000108  [13800/31359]\n",
      "loss: 0.000101  [13950/31359]\n",
      "loss: 0.000100  [14100/31359]\n",
      "loss: 0.013491  [14250/31359]\n",
      "loss: 0.000089  [14400/31359]\n",
      "loss: 0.000082  [14550/31359]\n",
      "loss: 0.000078  [14700/31359]\n",
      "loss: 0.011230  [14850/31359]\n",
      "loss: 0.000072  [15000/31359]\n",
      "loss: 0.009763  [15150/31359]\n",
      "loss: 0.000066  [15300/31359]\n",
      "loss: 0.007823  [15450/31359]\n",
      "loss: 0.000062  [15600/31359]\n",
      "loss: 0.000060  [15750/31359]\n",
      "loss: 0.014335  [15900/31359]\n",
      "loss: 0.000059  [16050/31359]\n",
      "loss: 0.000064  [16200/31359]\n",
      "loss: 0.000056  [16350/31359]\n",
      "loss: 0.000060  [16500/31359]\n",
      "loss: 0.012687  [16650/31359]\n",
      "loss: 0.010336  [16800/31359]\n",
      "loss: 0.000081  [16950/31359]\n",
      "loss: 0.000096  [17100/31359]\n",
      "loss: 0.000109  [17250/31359]\n",
      "loss: 0.000119  [17400/31359]\n",
      "loss: 0.000134  [17550/31359]\n",
      "loss: 0.016164  [17700/31359]\n",
      "loss: 0.005481  [17850/31359]\n",
      "loss: 0.000185  [18000/31359]\n",
      "loss: 0.000167  [18150/31359]\n",
      "loss: 0.000159  [18300/31359]\n",
      "loss: 0.000170  [18450/31359]\n",
      "loss: 0.000166  [18600/31359]\n",
      "loss: 0.000176  [18750/31359]\n",
      "loss: 0.007631  [18900/31359]\n",
      "loss: 0.000132  [19050/31359]\n",
      "loss: 0.000113  [19200/31359]\n",
      "loss: 0.000092  [19350/31359]\n",
      "loss: 0.017842  [19500/31359]\n",
      "loss: 0.000093  [19650/31359]\n",
      "loss: 0.004144  [19800/31359]\n",
      "loss: 0.000082  [19950/31359]\n",
      "loss: 0.007359  [20100/31359]\n",
      "loss: 0.000070  [20250/31359]\n",
      "loss: 0.000071  [20400/31359]\n",
      "loss: 0.000074  [20550/31359]\n",
      "loss: 0.026389  [20700/31359]\n",
      "loss: 0.000056  [20850/31359]\n",
      "loss: 0.000062  [21000/31359]\n",
      "loss: 0.000064  [21150/31359]\n",
      "loss: 0.020980  [21300/31359]\n",
      "loss: 0.000081  [21450/31359]\n",
      "loss: 0.000077  [21600/31359]\n",
      "loss: 0.014857  [21750/31359]\n",
      "loss: 0.000093  [21900/31359]\n",
      "loss: 0.007739  [22050/31359]\n",
      "loss: 0.000107  [22200/31359]\n",
      "loss: 0.007901  [22350/31359]\n",
      "loss: 0.000118  [22500/31359]\n",
      "loss: 0.000120  [22650/31359]\n",
      "loss: 0.000116  [22800/31359]\n",
      "loss: 0.000111  [22950/31359]\n",
      "loss: 0.000096  [23100/31359]\n",
      "loss: 0.000082  [23250/31359]\n",
      "loss: 0.000087  [23400/31359]\n",
      "loss: 0.000063  [23550/31359]\n",
      "loss: 0.000071  [23700/31359]\n",
      "loss: 0.000065  [23850/31359]\n",
      "loss: 0.000061  [24000/31359]\n",
      "loss: 0.000050  [24150/31359]\n",
      "loss: 0.000055  [24300/31359]\n",
      "loss: 0.010209  [24450/31359]\n",
      "loss: 0.000062  [24600/31359]\n",
      "loss: 0.009521  [24750/31359]\n",
      "loss: 0.000055  [24900/31359]\n",
      "loss: 0.000050  [25050/31359]\n",
      "loss: 0.000048  [25200/31359]\n",
      "loss: 0.000044  [25350/31359]\n",
      "loss: 0.000048  [25500/31359]\n",
      "loss: 0.000053  [25650/31359]\n",
      "loss: 0.006782  [25800/31359]\n",
      "loss: 0.000043  [25950/31359]\n",
      "loss: 0.000041  [26100/31359]\n",
      "loss: 0.000041  [26250/31359]\n",
      "loss: 0.000041  [26400/31359]\n",
      "loss: 0.000044  [26550/31359]\n",
      "loss: 0.004639  [26700/31359]\n",
      "loss: 0.016643  [26850/31359]\n",
      "loss: 0.000052  [27000/31359]\n",
      "loss: 0.000065  [27150/31359]\n",
      "loss: 0.000072  [27300/31359]\n",
      "loss: 0.000099  [27450/31359]\n",
      "loss: 0.011016  [27600/31359]\n",
      "loss: 0.000156  [27750/31359]\n",
      "loss: 0.000122  [27900/31359]\n",
      "loss: 0.000119  [28050/31359]\n",
      "loss: 0.007500  [28200/31359]\n",
      "loss: 0.000093  [28350/31359]\n",
      "loss: 0.000082  [28500/31359]\n",
      "loss: 0.000075  [28650/31359]\n",
      "loss: 0.000068  [28800/31359]\n",
      "loss: 0.000062  [28950/31359]\n",
      "loss: 0.002718  [29100/31359]\n",
      "loss: 0.000055  [29250/31359]\n",
      "loss: 0.001983  [29400/31359]\n",
      "loss: 0.000049  [29550/31359]\n",
      "loss: 0.000048  [29700/31359]\n",
      "loss: 0.000049  [29850/31359]\n",
      "loss: 0.000046  [30000/31359]\n",
      "loss: 0.001090  [30150/31359]\n",
      "loss: 0.000046  [30300/31359]\n",
      "loss: 0.000046  [30450/31359]\n",
      "loss: 0.000046  [30600/31359]\n",
      "loss: 0.000049  [30750/31359]\n",
      "loss: 0.001754  [30900/31359]\n",
      "loss: 0.026702  [31050/31359]\n",
      "loss: 0.000071  [31200/31359]\n",
      "loss: 0.000086  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.003624  [    0/31359]\n",
      "loss: 0.003869  [  150/31359]\n",
      "loss: 0.003804  [  300/31359]\n",
      "loss: 0.000102  [  450/31359]\n",
      "loss: 0.003184  [  600/31359]\n",
      "loss: 0.002815  [  750/31359]\n",
      "loss: 0.000067  [  900/31359]\n",
      "loss: 0.000062  [ 1050/31359]\n",
      "loss: 0.046885  [ 1200/31359]\n",
      "loss: 0.003813  [ 1350/31359]\n",
      "loss: 0.000116  [ 1500/31359]\n",
      "loss: 0.000149  [ 1650/31359]\n",
      "loss: 0.000172  [ 1800/31359]\n",
      "loss: 0.013370  [ 1950/31359]\n",
      "loss: 0.000147  [ 2100/31359]\n",
      "loss: 0.000122  [ 2250/31359]\n",
      "loss: 0.000099  [ 2400/31359]\n",
      "loss: 0.018880  [ 2550/31359]\n",
      "loss: 0.000061  [ 2700/31359]\n",
      "loss: 0.000044  [ 2850/31359]\n",
      "loss: 0.035874  [ 3000/31359]\n",
      "loss: 0.000056  [ 3150/31359]\n",
      "loss: 0.000066  [ 3300/31359]\n",
      "loss: 0.000092  [ 3450/31359]\n",
      "loss: 0.010861  [ 3600/31359]\n",
      "loss: 0.000178  [ 3750/31359]\n",
      "loss: 0.008112  [ 3900/31359]\n",
      "loss: 0.000265  [ 4050/31359]\n",
      "loss: 0.006942  [ 4200/31359]\n",
      "loss: 0.006595  [ 4350/31359]\n",
      "loss: 0.000110  [ 4500/31359]\n",
      "loss: 0.000086  [ 4650/31359]\n",
      "loss: 0.000071  [ 4800/31359]\n",
      "loss: 0.016215  [ 4950/31359]\n",
      "loss: 0.000059  [ 5100/31359]\n",
      "loss: 0.000056  [ 5250/31359]\n",
      "loss: 0.000057  [ 5400/31359]\n",
      "loss: 0.000053  [ 5550/31359]\n",
      "loss: 0.007128  [ 5700/31359]\n",
      "loss: 0.006946  [ 5850/31359]\n",
      "loss: 0.000048  [ 6000/31359]\n",
      "loss: 0.000052  [ 6150/31359]\n",
      "loss: 0.000050  [ 6300/31359]\n",
      "loss: 0.000048  [ 6450/31359]\n",
      "loss: 0.007171  [ 6600/31359]\n",
      "loss: 0.000050  [ 6750/31359]\n",
      "loss: 0.000046  [ 6900/31359]\n",
      "loss: 0.000046  [ 7050/31359]\n",
      "loss: 0.000047  [ 7200/31359]\n",
      "loss: 0.013867  [ 7350/31359]\n",
      "loss: 0.000045  [ 7500/31359]\n",
      "loss: 0.000044  [ 7650/31359]\n",
      "loss: 0.000049  [ 7800/31359]\n",
      "loss: 0.000047  [ 7950/31359]\n",
      "loss: 0.000048  [ 8100/31359]\n",
      "loss: 0.006918  [ 8250/31359]\n",
      "loss: 0.005831  [ 8400/31359]\n",
      "loss: 0.000045  [ 8550/31359]\n",
      "loss: 0.005248  [ 8700/31359]\n",
      "loss: 0.000066  [ 8850/31359]\n",
      "loss: 0.000082  [ 9000/31359]\n",
      "loss: 0.000117  [ 9150/31359]\n",
      "loss: 0.000149  [ 9300/31359]\n",
      "loss: 0.000171  [ 9450/31359]\n",
      "loss: 0.000169  [ 9600/31359]\n",
      "loss: 0.000144  [ 9750/31359]\n",
      "loss: 0.000118  [ 9900/31359]\n",
      "loss: 0.000097  [10050/31359]\n",
      "loss: 0.011711  [10200/31359]\n",
      "loss: 0.000068  [10350/31359]\n",
      "loss: 0.000059  [10500/31359]\n",
      "loss: 0.000054  [10650/31359]\n",
      "loss: 0.045113  [10800/31359]\n",
      "loss: 0.000060  [10950/31359]\n",
      "loss: 0.000071  [11100/31359]\n",
      "loss: 0.004831  [11250/31359]\n",
      "loss: 0.000092  [11400/31359]\n",
      "loss: 0.000094  [11550/31359]\n",
      "loss: 0.000095  [11700/31359]\n",
      "loss: 0.014305  [11850/31359]\n",
      "loss: 0.000095  [12000/31359]\n",
      "loss: 0.000090  [12150/31359]\n",
      "loss: 0.010301  [12300/31359]\n",
      "loss: 0.000074  [12450/31359]\n",
      "loss: 0.018768  [12600/31359]\n",
      "loss: 0.000067  [12750/31359]\n",
      "loss: 0.000070  [12900/31359]\n",
      "loss: 0.000084  [13050/31359]\n",
      "loss: 0.000088  [13200/31359]\n",
      "loss: 0.000112  [13350/31359]\n",
      "loss: 0.000125  [13500/31359]\n",
      "loss: 0.000126  [13650/31359]\n",
      "loss: 0.000118  [13800/31359]\n",
      "loss: 0.000103  [13950/31359]\n",
      "loss: 0.000092  [14100/31359]\n",
      "loss: 0.013903  [14250/31359]\n",
      "loss: 0.000073  [14400/31359]\n",
      "loss: 0.000064  [14550/31359]\n",
      "loss: 0.000059  [14700/31359]\n",
      "loss: 0.011532  [14850/31359]\n",
      "loss: 0.000051  [15000/31359]\n",
      "loss: 0.009670  [15150/31359]\n",
      "loss: 0.000046  [15300/31359]\n",
      "loss: 0.007750  [15450/31359]\n",
      "loss: 0.000042  [15600/31359]\n",
      "loss: 0.000041  [15750/31359]\n",
      "loss: 0.014878  [15900/31359]\n",
      "loss: 0.000041  [16050/31359]\n",
      "loss: 0.000045  [16200/31359]\n",
      "loss: 0.000039  [16350/31359]\n",
      "loss: 0.000043  [16500/31359]\n",
      "loss: 0.012616  [16650/31359]\n",
      "loss: 0.010021  [16800/31359]\n",
      "loss: 0.000071  [16950/31359]\n",
      "loss: 0.000095  [17100/31359]\n",
      "loss: 0.000120  [17250/31359]\n",
      "loss: 0.000139  [17400/31359]\n",
      "loss: 0.000165  [17550/31359]\n",
      "loss: 0.016927  [17700/31359]\n",
      "loss: 0.005189  [17850/31359]\n",
      "loss: 0.000188  [18000/31359]\n",
      "loss: 0.000137  [18150/31359]\n",
      "loss: 0.000120  [18300/31359]\n",
      "loss: 0.000128  [18450/31359]\n",
      "loss: 0.000128  [18600/31359]\n",
      "loss: 0.000141  [18750/31359]\n",
      "loss: 0.007588  [18900/31359]\n",
      "loss: 0.000108  [19050/31359]\n",
      "loss: 0.000092  [19200/31359]\n",
      "loss: 0.000074  [19350/31359]\n",
      "loss: 0.018461  [19500/31359]\n",
      "loss: 0.000076  [19650/31359]\n",
      "loss: 0.003946  [19800/31359]\n",
      "loss: 0.000069  [19950/31359]\n",
      "loss: 0.007030  [20100/31359]\n",
      "loss: 0.000057  [20250/31359]\n",
      "loss: 0.000057  [20400/31359]\n",
      "loss: 0.000059  [20550/31359]\n",
      "loss: 0.027163  [20700/31359]\n",
      "loss: 0.000044  [20850/31359]\n",
      "loss: 0.000051  [21000/31359]\n",
      "loss: 0.000053  [21150/31359]\n",
      "loss: 0.020924  [21300/31359]\n",
      "loss: 0.000073  [21450/31359]\n",
      "loss: 0.000074  [21600/31359]\n",
      "loss: 0.014639  [21750/31359]\n",
      "loss: 0.000098  [21900/31359]\n",
      "loss: 0.007867  [22050/31359]\n",
      "loss: 0.000115  [22200/31359]\n",
      "loss: 0.008031  [22350/31359]\n",
      "loss: 0.000117  [22500/31359]\n",
      "loss: 0.000110  [22650/31359]\n",
      "loss: 0.000101  [22800/31359]\n",
      "loss: 0.000091  [22950/31359]\n",
      "loss: 0.000074  [23100/31359]\n",
      "loss: 0.000061  [23250/31359]\n",
      "loss: 0.000063  [23400/31359]\n",
      "loss: 0.000044  [23550/31359]\n",
      "loss: 0.000050  [23700/31359]\n",
      "loss: 0.000046  [23850/31359]\n",
      "loss: 0.000043  [24000/31359]\n",
      "loss: 0.000035  [24150/31359]\n",
      "loss: 0.000039  [24300/31359]\n",
      "loss: 0.009983  [24450/31359]\n",
      "loss: 0.000045  [24600/31359]\n",
      "loss: 0.009307  [24750/31359]\n",
      "loss: 0.000040  [24900/31359]\n",
      "loss: 0.000036  [25050/31359]\n",
      "loss: 0.000034  [25200/31359]\n",
      "loss: 0.000032  [25350/31359]\n",
      "loss: 0.000035  [25500/31359]\n",
      "loss: 0.000039  [25650/31359]\n",
      "loss: 0.006630  [25800/31359]\n",
      "loss: 0.000031  [25950/31359]\n",
      "loss: 0.000029  [26100/31359]\n",
      "loss: 0.000029  [26250/31359]\n",
      "loss: 0.000029  [26400/31359]\n",
      "loss: 0.000032  [26550/31359]\n",
      "loss: 0.004594  [26700/31359]\n",
      "loss: 0.016631  [26850/31359]\n",
      "loss: 0.000041  [27000/31359]\n",
      "loss: 0.000057  [27150/31359]\n",
      "loss: 0.000071  [27300/31359]\n",
      "loss: 0.000113  [27450/31359]\n",
      "loss: 0.011504  [27600/31359]\n",
      "loss: 0.000210  [27750/31359]\n",
      "loss: 0.000137  [27900/31359]\n",
      "loss: 0.000120  [28050/31359]\n",
      "loss: 0.007742  [28200/31359]\n",
      "loss: 0.000076  [28350/31359]\n",
      "loss: 0.000063  [28500/31359]\n",
      "loss: 0.000056  [28650/31359]\n",
      "loss: 0.000049  [28800/31359]\n",
      "loss: 0.000045  [28950/31359]\n",
      "loss: 0.002632  [29100/31359]\n",
      "loss: 0.000040  [29250/31359]\n",
      "loss: 0.001879  [29400/31359]\n",
      "loss: 0.000035  [29550/31359]\n",
      "loss: 0.000035  [29700/31359]\n",
      "loss: 0.000036  [29850/31359]\n",
      "loss: 0.000033  [30000/31359]\n",
      "loss: 0.000994  [30150/31359]\n",
      "loss: 0.000034  [30300/31359]\n",
      "loss: 0.000034  [30450/31359]\n",
      "loss: 0.000034  [30600/31359]\n",
      "loss: 0.000037  [30750/31359]\n",
      "loss: 0.001726  [30900/31359]\n",
      "loss: 0.026619  [31050/31359]\n",
      "loss: 0.000057  [31200/31359]\n",
      "loss: 0.000073  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.003714  [    0/31359]\n",
      "loss: 0.003976  [  150/31359]\n",
      "loss: 0.003914  [  300/31359]\n",
      "loss: 0.000098  [  450/31359]\n",
      "loss: 0.003279  [  600/31359]\n",
      "loss: 0.002899  [  750/31359]\n",
      "loss: 0.000057  [  900/31359]\n",
      "loss: 0.000051  [ 1050/31359]\n",
      "loss: 0.046232  [ 1200/31359]\n",
      "loss: 0.003864  [ 1350/31359]\n",
      "loss: 0.000094  [ 1500/31359]\n",
      "loss: 0.000119  [ 1650/31359]\n",
      "loss: 0.000136  [ 1800/31359]\n",
      "loss: 0.013240  [ 1950/31359]\n",
      "loss: 0.000109  [ 2100/31359]\n",
      "loss: 0.000087  [ 2250/31359]\n",
      "loss: 0.000070  [ 2400/31359]\n",
      "loss: 0.018030  [ 2550/31359]\n",
      "loss: 0.000040  [ 2700/31359]\n",
      "loss: 0.000028  [ 2850/31359]\n",
      "loss: 0.041304  [ 3000/31359]\n",
      "loss: 0.000038  [ 3150/31359]\n",
      "loss: 0.000049  [ 3300/31359]\n",
      "loss: 0.000081  [ 3450/31359]\n",
      "loss: 0.009991  [ 3600/31359]\n",
      "loss: 0.000348  [ 3750/31359]\n",
      "loss: 0.007502  [ 3900/31359]\n",
      "loss: 0.000229  [ 4050/31359]\n",
      "loss: 0.006209  [ 4200/31359]\n",
      "loss: 0.005913  [ 4350/31359]\n",
      "loss: 0.000055  [ 4500/31359]\n",
      "loss: 0.000045  [ 4650/31359]\n",
      "loss: 0.000039  [ 4800/31359]\n",
      "loss: 0.017576  [ 4950/31359]\n",
      "loss: 0.000035  [ 5100/31359]\n",
      "loss: 0.000034  [ 5250/31359]\n",
      "loss: 0.000035  [ 5400/31359]\n",
      "loss: 0.000033  [ 5550/31359]\n",
      "loss: 0.007388  [ 5700/31359]\n",
      "loss: 0.007202  [ 5850/31359]\n",
      "loss: 0.000032  [ 6000/31359]\n",
      "loss: 0.000036  [ 6150/31359]\n",
      "loss: 0.000035  [ 6300/31359]\n",
      "loss: 0.000034  [ 6450/31359]\n",
      "loss: 0.007381  [ 6600/31359]\n",
      "loss: 0.000037  [ 6750/31359]\n",
      "loss: 0.000034  [ 6900/31359]\n",
      "loss: 0.000034  [ 7050/31359]\n",
      "loss: 0.000036  [ 7200/31359]\n",
      "loss: 0.013873  [ 7350/31359]\n",
      "loss: 0.000034  [ 7500/31359]\n",
      "loss: 0.000034  [ 7650/31359]\n",
      "loss: 0.000038  [ 7800/31359]\n",
      "loss: 0.000036  [ 7950/31359]\n",
      "loss: 0.000037  [ 8100/31359]\n",
      "loss: 0.006689  [ 8250/31359]\n",
      "loss: 0.005582  [ 8400/31359]\n",
      "loss: 0.000034  [ 8550/31359]\n",
      "loss: 0.005129  [ 8700/31359]\n",
      "loss: 0.000056  [ 8850/31359]\n",
      "loss: 0.000083  [ 9000/31359]\n",
      "loss: 0.000147  [ 9150/31359]\n",
      "loss: 0.000216  [ 9300/31359]\n",
      "loss: 0.000227  [ 9450/31359]\n",
      "loss: 0.000171  [ 9600/31359]\n",
      "loss: 0.000115  [ 9750/31359]\n",
      "loss: 0.000082  [ 9900/31359]\n",
      "loss: 0.000063  [10050/31359]\n",
      "loss: 0.010495  [10200/31359]\n",
      "loss: 0.000044  [10350/31359]\n",
      "loss: 0.000039  [10500/31359]\n",
      "loss: 0.000036  [10650/31359]\n",
      "loss: 0.049408  [10800/31359]\n",
      "loss: 0.000041  [10950/31359]\n",
      "loss: 0.000050  [11100/31359]\n",
      "loss: 0.004711  [11250/31359]\n",
      "loss: 0.000076  [11400/31359]\n",
      "loss: 0.000084  [11550/31359]\n",
      "loss: 0.000090  [11700/31359]\n",
      "loss: 0.014026  [11850/31359]\n",
      "loss: 0.000087  [12000/31359]\n",
      "loss: 0.000078  [12150/31359]\n",
      "loss: 0.009852  [12300/31359]\n",
      "loss: 0.000057  [12450/31359]\n",
      "loss: 0.018957  [12600/31359]\n",
      "loss: 0.000051  [12750/31359]\n",
      "loss: 0.000057  [12900/31359]\n",
      "loss: 0.000078  [13050/31359]\n",
      "loss: 0.000095  [13200/31359]\n",
      "loss: 0.000148  [13350/31359]\n",
      "loss: 0.000181  [13500/31359]\n",
      "loss: 0.000160  [13650/31359]\n",
      "loss: 0.000122  [13800/31359]\n",
      "loss: 0.000091  [13950/31359]\n",
      "loss: 0.000072  [14100/31359]\n",
      "loss: 0.014318  [14250/31359]\n",
      "loss: 0.000051  [14400/31359]\n",
      "loss: 0.000044  [14550/31359]\n",
      "loss: 0.000040  [14700/31359]\n",
      "loss: 0.011652  [14850/31359]\n",
      "loss: 0.000035  [15000/31359]\n",
      "loss: 0.009899  [15150/31359]\n",
      "loss: 0.000031  [15300/31359]\n",
      "loss: 0.007418  [15450/31359]\n",
      "loss: 0.000029  [15600/31359]\n",
      "loss: 0.000029  [15750/31359]\n",
      "loss: 0.015939  [15900/31359]\n",
      "loss: 0.000029  [16050/31359]\n",
      "loss: 0.000032  [16200/31359]\n",
      "loss: 0.000029  [16350/31359]\n",
      "loss: 0.000032  [16500/31359]\n",
      "loss: 0.012492  [16650/31359]\n",
      "loss: 0.009602  [16800/31359]\n",
      "loss: 0.000065  [16950/31359]\n",
      "loss: 0.000103  [17100/31359]\n",
      "loss: 0.000154  [17250/31359]\n",
      "loss: 0.000182  [17400/31359]\n",
      "loss: 0.000208  [17550/31359]\n",
      "loss: 0.017954  [17700/31359]\n",
      "loss: 0.005642  [17850/31359]\n",
      "loss: 0.000167  [18000/31359]\n",
      "loss: 0.000112  [18150/31359]\n",
      "loss: 0.000082  [18300/31359]\n",
      "loss: 0.000069  [18450/31359]\n",
      "loss: 0.000054  [18600/31359]\n",
      "loss: 0.000049  [18750/31359]\n",
      "loss: 0.000740  [18900/31359]\n",
      "loss: 0.000037  [19050/31359]\n",
      "loss: 0.000033  [19200/31359]\n",
      "loss: 0.000029  [19350/31359]\n",
      "loss: 0.085221  [19500/31359]\n",
      "loss: 0.000110  [19650/31359]\n",
      "loss: 0.006189  [19800/31359]\n",
      "loss: 0.000075  [19950/31359]\n",
      "loss: 0.001403  [20100/31359]\n",
      "loss: 0.000026  [20250/31359]\n",
      "loss: 0.000026  [20400/31359]\n",
      "loss: 0.000028  [20550/31359]\n",
      "loss: 0.050945  [20700/31359]\n",
      "loss: 0.000023  [20850/31359]\n",
      "loss: 0.000024  [21000/31359]\n",
      "loss: 0.000024  [21150/31359]\n",
      "loss: 0.003683  [21300/31359]\n",
      "loss: 0.000026  [21450/31359]\n",
      "loss: 0.000025  [21600/31359]\n",
      "loss: 0.000867  [21750/31359]\n",
      "loss: 0.000026  [21900/31359]\n",
      "loss: 0.044567  [22050/31359]\n",
      "loss: 0.000026  [22200/31359]\n",
      "loss: 0.021846  [22350/31359]\n",
      "loss: 0.000038  [22500/31359]\n",
      "loss: 0.000068  [22650/31359]\n",
      "loss: 0.000190  [22800/31359]\n",
      "loss: 0.000565  [22950/31359]\n",
      "loss: 0.000651  [23100/31359]\n",
      "loss: 0.000311  [23250/31359]\n",
      "loss: 0.000190  [23400/31359]\n",
      "loss: 0.000096  [23550/31359]\n",
      "loss: 0.000090  [23700/31359]\n",
      "loss: 0.000072  [23850/31359]\n",
      "loss: 0.000062  [24000/31359]\n",
      "loss: 0.000047  [24150/31359]\n",
      "loss: 0.000049  [24300/31359]\n",
      "loss: 0.027523  [24450/31359]\n",
      "loss: 0.000062  [24600/31359]\n",
      "loss: 0.021009  [24750/31359]\n",
      "loss: 0.000120  [24900/31359]\n",
      "loss: 0.000219  [25050/31359]\n",
      "loss: 0.000312  [25200/31359]\n",
      "loss: 0.000226  [25350/31359]\n",
      "loss: 0.000131  [25500/31359]\n",
      "loss: 0.000100  [25650/31359]\n",
      "loss: 0.008498  [25800/31359]\n",
      "loss: 0.000096  [25950/31359]\n",
      "loss: 0.000103  [26100/31359]\n",
      "loss: 0.000105  [26250/31359]\n",
      "loss: 0.000103  [26400/31359]\n",
      "loss: 0.000095  [26550/31359]\n",
      "loss: 0.004526  [26700/31359]\n",
      "loss: 0.017403  [26850/31359]\n",
      "loss: 0.000072  [27000/31359]\n",
      "loss: 0.000066  [27150/31359]\n",
      "loss: 0.000059  [27300/31359]\n",
      "loss: 0.000058  [27450/31359]\n",
      "loss: 0.009240  [27600/31359]\n",
      "loss: 0.000058  [27750/31359]\n",
      "loss: 0.000056  [27900/31359]\n",
      "loss: 0.000064  [28050/31359]\n",
      "loss: 0.005608  [28200/31359]\n",
      "loss: 0.000080  [28350/31359]\n",
      "loss: 0.000086  [28500/31359]\n",
      "loss: 0.000086  [28650/31359]\n",
      "loss: 0.000088  [28800/31359]\n",
      "loss: 0.000089  [28950/31359]\n",
      "loss: 0.002208  [29100/31359]\n",
      "loss: 0.000081  [29250/31359]\n",
      "loss: 0.001713  [29400/31359]\n",
      "loss: 0.000064  [29550/31359]\n",
      "loss: 0.000062  [29700/31359]\n",
      "loss: 0.000065  [29850/31359]\n",
      "loss: 0.000056  [30000/31359]\n",
      "loss: 0.001059  [30150/31359]\n",
      "loss: 0.000057  [30300/31359]\n",
      "loss: 0.000056  [30450/31359]\n",
      "loss: 0.000056  [30600/31359]\n",
      "loss: 0.000061  [30750/31359]\n",
      "loss: 0.001598  [30900/31359]\n",
      "loss: 0.028207  [31050/31359]\n",
      "loss: 0.000095  [31200/31359]\n",
      "loss: 0.000107  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.003150  [    0/31359]\n",
      "loss: 0.003374  [  150/31359]\n",
      "loss: 0.003334  [  300/31359]\n",
      "loss: 0.000109  [  450/31359]\n",
      "loss: 0.002858  [  600/31359]\n",
      "loss: 0.002571  [  750/31359]\n",
      "loss: 0.000063  [  900/31359]\n",
      "loss: 0.000056  [ 1050/31359]\n",
      "loss: 0.047915  [ 1200/31359]\n",
      "loss: 0.003702  [ 1350/31359]\n",
      "loss: 0.000077  [ 1500/31359]\n",
      "loss: 0.000089  [ 1650/31359]\n",
      "loss: 0.000100  [ 1800/31359]\n",
      "loss: 0.012954  [ 1950/31359]\n",
      "loss: 0.000097  [ 2100/31359]\n",
      "loss: 0.000087  [ 2250/31359]\n",
      "loss: 0.000076  [ 2400/31359]\n",
      "loss: 0.017549  [ 2550/31359]\n",
      "loss: 0.000048  [ 2700/31359]\n",
      "loss: 0.000034  [ 2850/31359]\n",
      "loss: 0.039935  [ 3000/31359]\n",
      "loss: 0.000046  [ 3150/31359]\n",
      "loss: 0.000058  [ 3300/31359]\n",
      "loss: 0.000092  [ 3450/31359]\n",
      "loss: 0.010593  [ 3600/31359]\n",
      "loss: 0.000309  [ 3750/31359]\n",
      "loss: 0.007908  [ 3900/31359]\n",
      "loss: 0.000280  [ 4050/31359]\n",
      "loss: 0.006608  [ 4200/31359]\n",
      "loss: 0.006291  [ 4350/31359]\n",
      "loss: 0.000066  [ 4500/31359]\n",
      "loss: 0.000053  [ 4650/31359]\n",
      "loss: 0.000047  [ 4800/31359]\n",
      "loss: 0.016775  [ 4950/31359]\n",
      "loss: 0.000040  [ 5100/31359]\n",
      "loss: 0.000039  [ 5250/31359]\n",
      "loss: 0.000039  [ 5400/31359]\n",
      "loss: 0.000036  [ 5550/31359]\n",
      "loss: 0.007459  [ 5700/31359]\n",
      "loss: 0.007217  [ 5850/31359]\n",
      "loss: 0.000035  [ 6000/31359]\n",
      "loss: 0.000037  [ 6150/31359]\n",
      "loss: 0.000037  [ 6300/31359]\n",
      "loss: 0.000036  [ 6450/31359]\n",
      "loss: 0.007275  [ 6600/31359]\n",
      "loss: 0.000038  [ 6750/31359]\n",
      "loss: 0.000036  [ 6900/31359]\n",
      "loss: 0.000036  [ 7050/31359]\n",
      "loss: 0.000037  [ 7200/31359]\n",
      "loss: 0.014087  [ 7350/31359]\n",
      "loss: 0.000036  [ 7500/31359]\n",
      "loss: 0.000035  [ 7650/31359]\n",
      "loss: 0.000038  [ 7800/31359]\n",
      "loss: 0.000037  [ 7950/31359]\n",
      "loss: 0.000037  [ 8100/31359]\n",
      "loss: 0.006555  [ 8250/31359]\n",
      "loss: 0.005437  [ 8400/31359]\n",
      "loss: 0.000034  [ 8550/31359]\n",
      "loss: 0.005024  [ 8700/31359]\n",
      "loss: 0.000052  [ 8850/31359]\n",
      "loss: 0.000069  [ 9000/31359]\n",
      "loss: 0.000111  [ 9150/31359]\n",
      "loss: 0.000164  [ 9300/31359]\n",
      "loss: 0.000206  [ 9450/31359]\n",
      "loss: 0.000196  [ 9600/31359]\n",
      "loss: 0.000154  [ 9750/31359]\n",
      "loss: 0.000114  [ 9900/31359]\n",
      "loss: 0.000087  [10050/31359]\n",
      "loss: 0.010194  [10200/31359]\n",
      "loss: 0.000058  [10350/31359]\n",
      "loss: 0.000051  [10500/31359]\n",
      "loss: 0.000047  [10650/31359]\n",
      "loss: 0.048282  [10800/31359]\n",
      "loss: 0.000050  [10950/31359]\n",
      "loss: 0.000059  [11100/31359]\n",
      "loss: 0.004569  [11250/31359]\n",
      "loss: 0.000077  [11400/31359]\n",
      "loss: 0.000081  [11550/31359]\n",
      "loss: 0.000083  [11700/31359]\n",
      "loss: 0.014361  [11850/31359]\n",
      "loss: 0.000079  [12000/31359]\n",
      "loss: 0.000074  [12150/31359]\n",
      "loss: 0.009995  [12300/31359]\n",
      "loss: 0.000058  [12450/31359]\n",
      "loss: 0.018915  [12600/31359]\n",
      "loss: 0.000054  [12750/31359]\n",
      "loss: 0.000059  [12900/31359]\n",
      "loss: 0.000078  [13050/31359]\n",
      "loss: 0.000090  [13200/31359]\n",
      "loss: 0.000132  [13350/31359]\n",
      "loss: 0.000161  [13500/31359]\n",
      "loss: 0.000155  [13650/31359]\n",
      "loss: 0.000130  [13800/31359]\n",
      "loss: 0.000104  [13950/31359]\n",
      "loss: 0.000084  [14100/31359]\n",
      "loss: 0.014221  [14250/31359]\n",
      "loss: 0.000060  [14400/31359]\n",
      "loss: 0.000052  [14550/31359]\n",
      "loss: 0.000047  [14700/31359]\n",
      "loss: 0.011643  [14850/31359]\n",
      "loss: 0.000040  [15000/31359]\n",
      "loss: 0.009790  [15150/31359]\n",
      "loss: 0.000036  [15300/31359]\n",
      "loss: 0.007543  [15450/31359]\n",
      "loss: 0.000033  [15600/31359]\n",
      "loss: 0.000032  [15750/31359]\n",
      "loss: 0.015550  [15900/31359]\n",
      "loss: 0.000032  [16050/31359]\n",
      "loss: 0.000036  [16200/31359]\n",
      "loss: 0.000031  [16350/31359]\n",
      "loss: 0.000035  [16500/31359]\n",
      "loss: 0.012577  [16650/31359]\n",
      "loss: 0.009749  [16800/31359]\n",
      "loss: 0.000060  [16950/31359]\n",
      "loss: 0.000086  [17100/31359]\n",
      "loss: 0.000119  [17250/31359]\n",
      "loss: 0.000147  [17400/31359]\n",
      "loss: 0.000184  [17550/31359]\n",
      "loss: 0.017804  [17700/31359]\n",
      "loss: 0.004860  [17850/31359]\n",
      "loss: 0.000179  [18000/31359]\n",
      "loss: 0.000118  [18150/31359]\n",
      "loss: 0.000102  [18300/31359]\n",
      "loss: 0.000110  [18450/31359]\n",
      "loss: 0.000114  [18600/31359]\n",
      "loss: 0.000131  [18750/31359]\n",
      "loss: 0.007564  [18900/31359]\n",
      "loss: 0.000105  [19050/31359]\n",
      "loss: 0.000090  [19200/31359]\n",
      "loss: 0.000072  [19350/31359]\n",
      "loss: 0.018837  [19500/31359]\n",
      "loss: 0.000075  [19650/31359]\n",
      "loss: 0.003821  [19800/31359]\n",
      "loss: 0.000067  [19950/31359]\n",
      "loss: 0.006818  [20100/31359]\n",
      "loss: 0.000055  [20250/31359]\n",
      "loss: 0.000055  [20400/31359]\n",
      "loss: 0.000057  [20550/31359]\n",
      "loss: 0.027375  [20700/31359]\n",
      "loss: 0.000043  [20850/31359]\n",
      "loss: 0.000049  [21000/31359]\n",
      "loss: 0.000051  [21150/31359]\n",
      "loss: 0.021051  [21300/31359]\n",
      "loss: 0.000070  [21450/31359]\n",
      "loss: 0.000070  [21600/31359]\n",
      "loss: 0.014685  [21750/31359]\n",
      "loss: 0.000090  [21900/31359]\n",
      "loss: 0.007891  [22050/31359]\n",
      "loss: 0.000104  [22200/31359]\n",
      "loss: 0.008050  [22350/31359]\n",
      "loss: 0.000107  [22500/31359]\n",
      "loss: 0.000102  [22650/31359]\n",
      "loss: 0.000093  [22800/31359]\n",
      "loss: 0.000085  [22950/31359]\n",
      "loss: 0.000068  [23100/31359]\n",
      "loss: 0.000055  [23250/31359]\n",
      "loss: 0.000057  [23400/31359]\n",
      "loss: 0.000039  [23550/31359]\n",
      "loss: 0.000045  [23700/31359]\n",
      "loss: 0.000041  [23850/31359]\n",
      "loss: 0.000038  [24000/31359]\n",
      "loss: 0.000031  [24150/31359]\n",
      "loss: 0.000035  [24300/31359]\n",
      "loss: 0.009961  [24450/31359]\n",
      "loss: 0.000041  [24600/31359]\n",
      "loss: 0.009285  [24750/31359]\n",
      "loss: 0.000035  [24900/31359]\n",
      "loss: 0.000031  [25050/31359]\n",
      "loss: 0.000029  [25200/31359]\n",
      "loss: 0.000027  [25350/31359]\n",
      "loss: 0.000030  [25500/31359]\n",
      "loss: 0.000034  [25650/31359]\n",
      "loss: 0.006615  [25800/31359]\n",
      "loss: 0.000027  [25950/31359]\n",
      "loss: 0.000025  [26100/31359]\n",
      "loss: 0.000025  [26250/31359]\n",
      "loss: 0.000025  [26400/31359]\n",
      "loss: 0.000027  [26550/31359]\n",
      "loss: 0.004591  [26700/31359]\n",
      "loss: 0.016615  [26850/31359]\n",
      "loss: 0.000036  [27000/31359]\n",
      "loss: 0.000052  [27150/31359]\n",
      "loss: 0.000067  [27300/31359]\n",
      "loss: 0.000113  [27450/31359]\n",
      "loss: 0.011529  [27600/31359]\n",
      "loss: 0.000200  [27750/31359]\n",
      "loss: 0.000132  [27900/31359]\n",
      "loss: 0.000111  [28050/31359]\n",
      "loss: 0.007649  [28200/31359]\n",
      "loss: 0.000067  [28350/31359]\n",
      "loss: 0.000056  [28500/31359]\n",
      "loss: 0.000049  [28650/31359]\n",
      "loss: 0.000043  [28800/31359]\n",
      "loss: 0.000040  [28950/31359]\n",
      "loss: 0.002558  [29100/31359]\n",
      "loss: 0.000036  [29250/31359]\n",
      "loss: 0.001832  [29400/31359]\n",
      "loss: 0.000032  [29550/31359]\n",
      "loss: 0.000031  [29700/31359]\n",
      "loss: 0.000033  [29850/31359]\n",
      "loss: 0.000030  [30000/31359]\n",
      "loss: 0.000981  [30150/31359]\n",
      "loss: 0.000031  [30300/31359]\n",
      "loss: 0.000031  [30450/31359]\n",
      "loss: 0.000031  [30600/31359]\n",
      "loss: 0.000033  [30750/31359]\n",
      "loss: 0.001700  [30900/31359]\n",
      "loss: 0.026791  [31050/31359]\n",
      "loss: 0.000052  [31200/31359]\n",
      "loss: 0.000067  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.003637  [    0/31359]\n",
      "loss: 0.003898  [  150/31359]\n",
      "loss: 0.003846  [  300/31359]\n",
      "loss: 0.000095  [  450/31359]\n",
      "loss: 0.003244  [  600/31359]\n",
      "loss: 0.002883  [  750/31359]\n",
      "loss: 0.000054  [  900/31359]\n",
      "loss: 0.000048  [ 1050/31359]\n",
      "loss: 0.046186  [ 1200/31359]\n",
      "loss: 0.003844  [ 1350/31359]\n",
      "loss: 0.000080  [ 1500/31359]\n",
      "loss: 0.000097  [ 1650/31359]\n",
      "loss: 0.000110  [ 1800/31359]\n",
      "loss: 0.013195  [ 1950/31359]\n",
      "loss: 0.000090  [ 2100/31359]\n",
      "loss: 0.000073  [ 2250/31359]\n",
      "loss: 0.000059  [ 2400/31359]\n",
      "loss: 0.017757  [ 2550/31359]\n",
      "loss: 0.000033  [ 2700/31359]\n",
      "loss: 0.000023  [ 2850/31359]\n",
      "loss: 0.042674  [ 3000/31359]\n",
      "loss: 0.000032  [ 3150/31359]\n",
      "loss: 0.000043  [ 3300/31359]\n",
      "loss: 0.000077  [ 3450/31359]\n",
      "loss: 0.009846  [ 3600/31359]\n",
      "loss: 0.000435  [ 3750/31359]\n",
      "loss: 0.007338  [ 3900/31359]\n",
      "loss: 0.000168  [ 4050/31359]\n",
      "loss: 0.006046  [ 4200/31359]\n",
      "loss: 0.005781  [ 4350/31359]\n",
      "loss: 0.000041  [ 4500/31359]\n",
      "loss: 0.000035  [ 4650/31359]\n",
      "loss: 0.000031  [ 4800/31359]\n",
      "loss: 0.017806  [ 4950/31359]\n",
      "loss: 0.000028  [ 5100/31359]\n",
      "loss: 0.000027  [ 5250/31359]\n",
      "loss: 0.000028  [ 5400/31359]\n",
      "loss: 0.000027  [ 5550/31359]\n",
      "loss: 0.007547  [ 5700/31359]\n",
      "loss: 0.007335  [ 5850/31359]\n",
      "loss: 0.000026  [ 6000/31359]\n",
      "loss: 0.000030  [ 6150/31359]\n",
      "loss: 0.000029  [ 6300/31359]\n",
      "loss: 0.000029  [ 6450/31359]\n",
      "loss: 0.007410  [ 6600/31359]\n",
      "loss: 0.000031  [ 6750/31359]\n",
      "loss: 0.000029  [ 6900/31359]\n",
      "loss: 0.000029  [ 7050/31359]\n",
      "loss: 0.000030  [ 7200/31359]\n",
      "loss: 0.013969  [ 7350/31359]\n",
      "loss: 0.000030  [ 7500/31359]\n",
      "loss: 0.000029  [ 7650/31359]\n",
      "loss: 0.000032  [ 7800/31359]\n",
      "loss: 0.000031  [ 7950/31359]\n",
      "loss: 0.000031  [ 8100/31359]\n",
      "loss: 0.006614  [ 8250/31359]\n",
      "loss: 0.005495  [ 8400/31359]\n",
      "loss: 0.000029  [ 8550/31359]\n",
      "loss: 0.005080  [ 8700/31359]\n",
      "loss: 0.000050  [ 8850/31359]\n",
      "loss: 0.000079  [ 9000/31359]\n",
      "loss: 0.000153  [ 9150/31359]\n",
      "loss: 0.000238  [ 9300/31359]\n",
      "loss: 0.000230  [ 9450/31359]\n",
      "loss: 0.000154  [ 9600/31359]\n",
      "loss: 0.000097  [ 9750/31359]\n",
      "loss: 0.000067  [ 9900/31359]\n",
      "loss: 0.000051  [10050/31359]\n",
      "loss: 0.010065  [10200/31359]\n",
      "loss: 0.000036  [10350/31359]\n",
      "loss: 0.000033  [10500/31359]\n",
      "loss: 0.000031  [10650/31359]\n",
      "loss: 0.050887  [10800/31359]\n",
      "loss: 0.000035  [10950/31359]\n",
      "loss: 0.000043  [11100/31359]\n",
      "loss: 0.004648  [11250/31359]\n",
      "loss: 0.000068  [11400/31359]\n",
      "loss: 0.000078  [11550/31359]\n",
      "loss: 0.000085  [11700/31359]\n",
      "loss: 0.013979  [11850/31359]\n",
      "loss: 0.000080  [12000/31359]\n",
      "loss: 0.000071  [12150/31359]\n",
      "loss: 0.009700  [12300/31359]\n",
      "loss: 0.000050  [12450/31359]\n",
      "loss: 0.019037  [12600/31359]\n",
      "loss: 0.000044  [12750/31359]\n",
      "loss: 0.000051  [12900/31359]\n",
      "loss: 0.000074  [13050/31359]\n",
      "loss: 0.000096  [13200/31359]\n",
      "loss: 0.000161  [13350/31359]\n",
      "loss: 0.000198  [13500/31359]\n",
      "loss: 0.000159  [13650/31359]\n",
      "loss: 0.000110  [13800/31359]\n",
      "loss: 0.000077  [13950/31359]\n",
      "loss: 0.000059  [14100/31359]\n",
      "loss: 0.014458  [14250/31359]\n",
      "loss: 0.000041  [14400/31359]\n",
      "loss: 0.000036  [14550/31359]\n",
      "loss: 0.000033  [14700/31359]\n",
      "loss: 0.011640  [14850/31359]\n",
      "loss: 0.000029  [15000/31359]\n",
      "loss: 0.010048  [15150/31359]\n",
      "loss: 0.000026  [15300/31359]\n",
      "loss: 0.007261  [15450/31359]\n",
      "loss: 0.000025  [15600/31359]\n",
      "loss: 0.000024  [15750/31359]\n",
      "loss: 0.016351  [15900/31359]\n",
      "loss: 0.000025  [16050/31359]\n",
      "loss: 0.000028  [16200/31359]\n",
      "loss: 0.000024  [16350/31359]\n",
      "loss: 0.000027  [16500/31359]\n",
      "loss: 0.012439  [16650/31359]\n",
      "loss: 0.009453  [16800/31359]\n",
      "loss: 0.000059  [16950/31359]\n",
      "loss: 0.000100  [17100/31359]\n",
      "loss: 0.000159  [17250/31359]\n",
      "loss: 0.000190  [17400/31359]\n",
      "loss: 0.000211  [17550/31359]\n",
      "loss: 0.018433  [17700/31359]\n",
      "loss: 0.004566  [17850/31359]\n",
      "loss: 0.000134  [18000/31359]\n",
      "loss: 0.000086  [18150/31359]\n",
      "loss: 0.000078  [18300/31359]\n",
      "loss: 0.000096  [18450/31359]\n",
      "loss: 0.000113  [18600/31359]\n",
      "loss: 0.000143  [18750/31359]\n",
      "loss: 0.007577  [18900/31359]\n",
      "loss: 0.000108  [19050/31359]\n",
      "loss: 0.000087  [19200/31359]\n",
      "loss: 0.000066  [19350/31359]\n",
      "loss: 0.019118  [19500/31359]\n",
      "loss: 0.000066  [19650/31359]\n",
      "loss: 0.003726  [19800/31359]\n",
      "loss: 0.000058  [19950/31359]\n",
      "loss: 0.006644  [20100/31359]\n",
      "loss: 0.000046  [20250/31359]\n",
      "loss: 0.000047  [20400/31359]\n",
      "loss: 0.000048  [20550/31359]\n",
      "loss: 0.027912  [20700/31359]\n",
      "loss: 0.000036  [20850/31359]\n",
      "loss: 0.000042  [21000/31359]\n",
      "loss: 0.000045  [21150/31359]\n",
      "loss: 0.020986  [21300/31359]\n",
      "loss: 0.000066  [21450/31359]\n",
      "loss: 0.000069  [21600/31359]\n",
      "loss: 0.014540  [21750/31359]\n",
      "loss: 0.000096  [21900/31359]\n",
      "loss: 0.007975  [22050/31359]\n",
      "loss: 0.000107  [22200/31359]\n",
      "loss: 0.008132  [22350/31359]\n",
      "loss: 0.000100  [22500/31359]\n",
      "loss: 0.000090  [22650/31359]\n",
      "loss: 0.000080  [22800/31359]\n",
      "loss: 0.000070  [22950/31359]\n",
      "loss: 0.000055  [23100/31359]\n",
      "loss: 0.000044  [23250/31359]\n",
      "loss: 0.000046  [23400/31359]\n",
      "loss: 0.000031  [23550/31359]\n",
      "loss: 0.000036  [23700/31359]\n",
      "loss: 0.000032  [23850/31359]\n",
      "loss: 0.000030  [24000/31359]\n",
      "loss: 0.000024  [24150/31359]\n",
      "loss: 0.000028  [24300/31359]\n",
      "loss: 0.009849  [24450/31359]\n",
      "loss: 0.000033  [24600/31359]\n",
      "loss: 0.009189  [24750/31359]\n",
      "loss: 0.000028  [24900/31359]\n",
      "loss: 0.000025  [25050/31359]\n",
      "loss: 0.000024  [25200/31359]\n",
      "loss: 0.000022  [25350/31359]\n",
      "loss: 0.000025  [25500/31359]\n",
      "loss: 0.000028  [25650/31359]\n",
      "loss: 0.006569  [25800/31359]\n",
      "loss: 0.000022  [25950/31359]\n",
      "loss: 0.000020  [26100/31359]\n",
      "loss: 0.000020  [26250/31359]\n",
      "loss: 0.000020  [26400/31359]\n",
      "loss: 0.000022  [26550/31359]\n",
      "loss: 0.004605  [26700/31359]\n",
      "loss: 0.016510  [26850/31359]\n",
      "loss: 0.000032  [27000/31359]\n",
      "loss: 0.000051  [27150/31359]\n",
      "loss: 0.000076  [27300/31359]\n",
      "loss: 0.000146  [27450/31359]\n",
      "loss: 0.011810  [27600/31359]\n",
      "loss: 0.000220  [27750/31359]\n",
      "loss: 0.000117  [27900/31359]\n",
      "loss: 0.000088  [28050/31359]\n",
      "loss: 0.007698  [28200/31359]\n",
      "loss: 0.000049  [28350/31359]\n",
      "loss: 0.000040  [28500/31359]\n",
      "loss: 0.000036  [28650/31359]\n",
      "loss: 0.000032  [28800/31359]\n",
      "loss: 0.000030  [28950/31359]\n",
      "loss: 0.002423  [29100/31359]\n",
      "loss: 0.000027  [29250/31359]\n",
      "loss: 0.001704  [29400/31359]\n",
      "loss: 0.000025  [29550/31359]\n",
      "loss: 0.000024  [29700/31359]\n",
      "loss: 0.000026  [29850/31359]\n",
      "loss: 0.000024  [30000/31359]\n",
      "loss: 0.000884  [30150/31359]\n",
      "loss: 0.000025  [30300/31359]\n",
      "loss: 0.000025  [30450/31359]\n",
      "loss: 0.000025  [30600/31359]\n",
      "loss: 0.000027  [30750/31359]\n",
      "loss: 0.001673  [30900/31359]\n",
      "loss: 0.026741  [31050/31359]\n",
      "loss: 0.000047  [31200/31359]\n",
      "loss: 0.000067  [ 3762/31359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.003732  [    0/31359]\n",
      "loss: 0.004010  [  150/31359]\n",
      "loss: 0.003950  [  300/31359]\n",
      "loss: 0.000096  [  450/31359]\n",
      "loss: 0.003311  [  600/31359]\n",
      "loss: 0.002936  [  750/31359]\n",
      "loss: 0.000045  [  900/31359]\n",
      "loss: 0.000039  [ 1050/31359]\n",
      "loss: 0.045728  [ 1200/31359]\n",
      "loss: 0.003922  [ 1350/31359]\n",
      "loss: 0.000058  [ 1500/31359]\n",
      "loss: 0.000068  [ 1650/31359]\n",
      "loss: 0.000080  [ 1800/31359]\n",
      "loss: 0.012938  [ 1950/31359]\n",
      "loss: 0.000071  [ 2100/31359]\n",
      "loss: 0.000058  [ 2250/31359]\n",
      "loss: 0.000047  [ 2400/31359]\n",
      "loss: 0.017156  [ 2550/31359]\n",
      "loss: 0.000026  [ 2700/31359]\n",
      "loss: 0.000018  [ 2850/31359]\n",
      "loss: 0.046957  [ 3000/31359]\n",
      "loss: 0.000026  [ 3150/31359]\n",
      "loss: 0.000037  [ 3300/31359]\n",
      "loss: 0.000085  [ 3450/31359]\n",
      "loss: 0.009213  [ 3600/31359]\n",
      "loss: 0.000692  [ 3750/31359]\n",
      "loss: 0.006709  [ 3900/31359]\n",
      "loss: 0.000068  [ 4050/31359]\n",
      "loss: 0.005630  [ 4200/31359]\n",
      "loss: 0.005455  [ 4350/31359]\n",
      "loss: 0.000026  [ 4500/31359]\n",
      "loss: 0.000024  [ 4650/31359]\n",
      "loss: 0.000022  [ 4800/31359]\n",
      "loss: 0.018360  [ 4950/31359]\n",
      "loss: 0.000021  [ 5100/31359]\n",
      "loss: 0.000020  [ 5250/31359]\n",
      "loss: 0.000021  [ 5400/31359]\n",
      "loss: 0.000020  [ 5550/31359]\n",
      "loss: 0.008232  [ 5700/31359]\n",
      "loss: 0.007878  [ 5850/31359]\n",
      "loss: 0.000020  [ 6000/31359]\n",
      "loss: 0.000023  [ 6150/31359]\n",
      "loss: 0.000022  [ 6300/31359]\n",
      "loss: 0.000022  [ 6450/31359]\n",
      "loss: 0.007414  [ 6600/31359]\n",
      "loss: 0.000024  [ 6750/31359]\n",
      "loss: 0.000023  [ 6900/31359]\n",
      "loss: 0.000023  [ 7050/31359]\n",
      "loss: 0.000025  [ 7200/31359]\n",
      "loss: 0.014462  [ 7350/31359]\n",
      "loss: 0.000024  [ 7500/31359]\n",
      "loss: 0.000024  [ 7650/31359]\n",
      "loss: 0.000027  [ 7800/31359]\n",
      "loss: 0.000026  [ 7950/31359]\n",
      "loss: 0.000026  [ 8100/31359]\n",
      "loss: 0.006411  [ 8250/31359]\n",
      "loss: 0.005248  [ 8400/31359]\n",
      "loss: 0.000024  [ 8550/31359]\n",
      "loss: 0.004955  [ 8700/31359]\n",
      "loss: 0.000046  [ 8850/31359]\n",
      "loss: 0.000092  [ 9000/31359]\n",
      "loss: 0.000241  [ 9150/31359]\n",
      "loss: 0.000348  [ 9300/31359]\n",
      "loss: 0.000200  [ 9450/31359]\n",
      "loss: 0.000098  [ 9600/31359]\n",
      "loss: 0.000058  [ 9750/31359]\n",
      "loss: 0.000042  [ 9900/31359]\n",
      "loss: 0.000034  [10050/31359]\n",
      "loss: 0.009120  [10200/31359]\n",
      "loss: 0.000027  [10350/31359]\n",
      "loss: 0.000025  [10500/31359]\n",
      "loss: 0.000024  [10650/31359]\n",
      "loss: 0.054780  [10800/31359]\n",
      "loss: 0.000027  [10950/31359]\n",
      "loss: 0.000034  [11100/31359]\n",
      "loss: 0.004583  [11250/31359]\n",
      "loss: 0.000059  [11400/31359]\n",
      "loss: 0.000073  [11550/31359]\n",
      "loss: 0.000084  [11700/31359]\n",
      "loss: 0.013772  [11850/31359]\n",
      "loss: 0.000074  [12000/31359]\n",
      "loss: 0.000062  [12150/31359]\n",
      "loss: 0.009366  [12300/31359]\n",
      "loss: 0.000040  [12450/31359]\n",
      "loss: 0.019259  [12600/31359]\n",
      "loss: 0.000036  [12750/31359]\n",
      "loss: 0.000045  [12900/31359]\n",
      "loss: 0.000075  [13050/31359]\n",
      "loss: 0.000123  [13200/31359]\n",
      "loss: 0.000260  [13350/31359]\n",
      "loss: 0.000263  [13500/31359]\n",
      "loss: 0.000134  [13650/31359]\n",
      "loss: 0.000074  [13800/31359]\n",
      "loss: 0.000049  [13950/31359]\n",
      "loss: 0.000038  [14100/31359]\n",
      "loss: 0.014600  [14250/31359]\n",
      "loss: 0.000028  [14400/31359]\n",
      "loss: 0.000025  [14550/31359]\n",
      "loss: 0.000023  [14700/31359]\n",
      "loss: 0.011318  [14850/31359]\n",
      "loss: 0.000021  [15000/31359]\n",
      "loss: 0.010873  [15150/31359]\n",
      "loss: 0.000020  [15300/31359]\n",
      "loss: 0.006623  [15450/31359]\n",
      "loss: 0.000019  [15600/31359]\n",
      "loss: 0.000019  [15750/31359]\n",
      "loss: 0.017964  [15900/31359]\n",
      "loss: 0.000019  [16050/31359]\n",
      "loss: 0.000022  [16200/31359]\n",
      "loss: 0.000019  [16350/31359]\n",
      "loss: 0.000021  [16500/31359]\n",
      "loss: 0.012048  [16650/31359]\n",
      "loss: 0.008799  [16800/31359]\n",
      "loss: 0.000048  [16950/31359]\n",
      "loss: 0.000090  [17100/31359]\n",
      "loss: 0.000165  [17250/31359]\n",
      "loss: 0.000212  [17400/31359]\n",
      "loss: 0.000241  [17550/31359]\n",
      "loss: 0.019798  [17700/31359]\n",
      "loss: 0.004175  [17850/31359]\n",
      "loss: 0.000129  [18000/31359]\n",
      "loss: 0.000076  [18150/31359]\n",
      "loss: 0.000069  [18300/31359]\n",
      "loss: 0.000087  [18450/31359]\n",
      "loss: 0.000097  [18600/31359]\n",
      "loss: 0.000111  [18750/31359]\n",
      "loss: 0.005031  [18900/31359]\n",
      "loss: 0.000065  [19050/31359]\n",
      "loss: 0.000049  [19200/31359]\n",
      "loss: 0.000038  [19350/31359]\n",
      "loss: 0.045963  [19500/31359]\n",
      "loss: 0.000208  [19650/31359]\n",
      "loss: 0.006203  [19800/31359]\n",
      "loss: 0.000063  [19950/31359]\n",
      "loss: 0.004395  [20100/31359]\n",
      "loss: 0.000023  [20250/31359]\n",
      "loss: 0.000024  [20400/31359]\n",
      "loss: 0.000026  [20550/31359]\n",
      "loss: 0.042748  [20700/31359]\n",
      "loss: 0.000019  [20850/31359]\n",
      "loss: 0.000020  [21000/31359]\n",
      "loss: 0.000020  [21150/31359]\n",
      "loss: 0.005629  [21300/31359]\n",
      "loss: 0.000021  [21450/31359]\n",
      "loss: 0.000018  [21600/31359]\n",
      "loss: 0.001550  [21750/31359]\n",
      "loss: 0.000018  [21900/31359]\n",
      "loss: 0.038196  [22050/31359]\n",
      "loss: 0.000018  [22200/31359]\n",
      "loss: 0.015556  [22350/31359]\n",
      "loss: 0.000025  [22500/31359]\n",
      "loss: 0.000035  [22650/31359]\n",
      "loss: 0.000055  [22800/31359]\n",
      "loss: 0.000100  [22950/31359]\n",
      "loss: 0.000223  [23100/31359]\n",
      "loss: 0.000526  [23250/31359]\n",
      "loss: 0.000468  [23400/31359]\n",
      "loss: 0.000133  [23550/31359]\n",
      "loss: 0.000096  [23700/31359]\n",
      "loss: 0.000065  [23850/31359]\n",
      "loss: 0.000051  [24000/31359]\n",
      "loss: 0.000035  [24150/31359]\n",
      "loss: 0.000038  [24300/31359]\n",
      "loss: 0.027464  [24450/31359]\n",
      "loss: 0.000049  [24600/31359]\n",
      "loss: 0.021013  [24750/31359]\n",
      "loss: 0.000098  [24900/31359]\n",
      "loss: 0.000201  [25050/31359]\n",
      "loss: 0.000303  [25200/31359]\n",
      "loss: 0.000182  [25350/31359]\n",
      "loss: 0.000095  [25500/31359]\n",
      "loss: 0.000074  [25650/31359]\n",
      "loss: 0.008477  [25800/31359]\n",
      "loss: 0.000067  [25950/31359]\n",
      "loss: 0.000071  [26100/31359]\n",
      "loss: 0.000074  [26250/31359]\n",
      "loss: 0.000073  [26400/31359]\n",
      "loss: 0.000071  [26550/31359]\n",
      "loss: 0.004244  [26700/31359]\n",
      "loss: 0.018058  [26850/31359]\n",
      "loss: 0.000057  [27000/31359]\n",
      "loss: 0.000055  [27150/31359]\n",
      "loss: 0.000048  [27300/31359]\n",
      "loss: 0.000051  [27450/31359]\n",
      "loss: 0.009629  [27600/31359]\n",
      "loss: 0.000051  [27750/31359]\n",
      "loss: 0.000048  [27900/31359]\n",
      "loss: 0.000054  [28050/31359]\n",
      "loss: 0.005961  [28200/31359]\n",
      "loss: 0.000062  [28350/31359]\n",
      "loss: 0.000065  [28500/31359]\n",
      "loss: 0.000064  [28650/31359]\n",
      "loss: 0.000062  [28800/31359]\n",
      "loss: 0.000060  [28950/31359]\n",
      "loss: 0.002235  [29100/31359]\n",
      "loss: 0.000053  [29250/31359]\n",
      "loss: 0.001692  [29400/31359]\n",
      "loss: 0.000042  [29550/31359]\n",
      "loss: 0.000040  [29700/31359]\n",
      "loss: 0.000042  [29850/31359]\n",
      "loss: 0.000037  [30000/31359]\n",
      "loss: 0.001001  [30150/31359]\n",
      "loss: 0.000038  [30300/31359]\n",
      "loss: 0.000037  [30450/31359]\n",
      "loss: 0.000038  [30600/31359]\n",
      "loss: 0.000043  [30750/31359]\n",
      "loss: 0.001612  [30900/31359]\n",
      "loss: 0.027802  [31050/31359]\n",
      "loss: 0.000091  [31200/31359]\n",
      "loss: 0.000129  [ 3762/31359]\n",
      "Accuracy: 45.45%\n",
      "Precision: 0.21\n",
      "Recall: 0.45\n",
      "F1 Score: 0.28\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_abd\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "model=MultiModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop2(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d18d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e1711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a4575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
